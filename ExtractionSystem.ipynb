{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jeDDiFoWWeD"
   },
   "source": [
    "# **Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user ipykernel\n",
    "# python -m ipykernel install --user --name=myenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting paddlepaddle\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/58/fb/d239e52422f704f4974b4b671f5516952c97fb06be7bc5e811e205a90c8d/paddlepaddle-2.5.2-cp38-cp38-win_amd64.whl (72.0 MB)\n",
      "     ---------------------------------------- 0.0/72.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/72.0 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/72.0 MB 326.8 kB/s eta 0:03:41\n",
      "     --------------------------------------- 0.1/72.0 MB 409.6 kB/s eta 0:02:56\n",
      "     --------------------------------------- 0.1/72.0 MB 595.3 kB/s eta 0:02:01\n",
      "     --------------------------------------- 0.2/72.0 MB 700.2 kB/s eta 0:01:43\n",
      "     --------------------------------------- 0.3/72.0 MB 874.6 kB/s eta 0:01:22\n",
      "     ---------------------------------------- 0.4/72.0 MB 1.0 MB/s eta 0:01:09\n",
      "     ---------------------------------------- 0.5/72.0 MB 1.4 MB/s eta 0:00:52\n",
      "     ---------------------------------------- 0.8/72.0 MB 1.8 MB/s eta 0:00:41\n",
      "      --------------------------------------- 1.2/72.0 MB 2.4 MB/s eta 0:00:31\n",
      "     - -------------------------------------- 1.8/72.0 MB 3.3 MB/s eta 0:00:22\n",
      "     - -------------------------------------- 2.3/72.0 MB 3.8 MB/s eta 0:00:19\n",
      "     - -------------------------------------- 3.1/72.0 MB 4.7 MB/s eta 0:00:15\n",
      "     -- ------------------------------------- 4.8/72.0 MB 6.7 MB/s eta 0:00:11\n",
      "     --- ------------------------------------ 5.6/72.0 MB 7.3 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 7.5/72.0 MB 9.1 MB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 8.4/72.0 MB 10.1 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 8.4/72.0 MB 10.1 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 8.5/72.0 MB 8.8 MB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 8.7/72.0 MB 9.0 MB/s eta 0:00:08\n",
      "     ---- ----------------------------------- 8.7/72.0 MB 9.0 MB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 9.6/72.0 MB 8.7 MB/s eta 0:00:08\n",
      "     ----- --------------------------------- 10.8/72.0 MB 14.2 MB/s eta 0:00:05\n",
      "     ------ -------------------------------- 11.5/72.0 MB 14.9 MB/s eta 0:00:05\n",
      "     ------ -------------------------------- 11.5/72.0 MB 14.9 MB/s eta 0:00:05\n",
      "     ------ -------------------------------- 12.4/72.0 MB 15.6 MB/s eta 0:00:04\n",
      "     ------ -------------------------------- 12.4/72.0 MB 15.6 MB/s eta 0:00:04\n",
      "     ------ -------------------------------- 12.4/72.0 MB 15.6 MB/s eta 0:00:04\n",
      "     ------- ------------------------------- 14.5/72.0 MB 14.2 MB/s eta 0:00:05\n",
      "     -------- ------------------------------ 14.9/72.0 MB 13.4 MB/s eta 0:00:05\n",
      "     -------- ------------------------------ 15.4/72.0 MB 13.6 MB/s eta 0:00:05\n",
      "     -------- ------------------------------ 15.4/72.0 MB 13.6 MB/s eta 0:00:05\n",
      "     -------- ------------------------------ 15.4/72.0 MB 13.6 MB/s eta 0:00:05\n",
      "     -------- ------------------------------ 15.4/72.0 MB 13.6 MB/s eta 0:00:05\n",
      "     -------- ------------------------------ 15.4/72.0 MB 13.6 MB/s eta 0:00:05\n",
      "     -------- ------------------------------ 15.4/72.0 MB 13.6 MB/s eta 0:00:05\n",
      "     ---------- ---------------------------- 18.6/72.0 MB 10.2 MB/s eta 0:00:06\n",
      "     ---------- ---------------------------- 18.6/72.0 MB 10.2 MB/s eta 0:00:06\n",
      "     ---------- ---------------------------- 20.0/72.0 MB 12.4 MB/s eta 0:00:05\n",
      "     ----------- --------------------------- 21.6/72.0 MB 13.4 MB/s eta 0:00:04\n",
      "     ------------ -------------------------- 23.1/72.0 MB 16.4 MB/s eta 0:00:03\n",
      "     ------------ -------------------------- 23.1/72.0 MB 16.4 MB/s eta 0:00:03\n",
      "     ------------ -------------------------- 23.1/72.0 MB 16.4 MB/s eta 0:00:03\n",
      "     ------------ -------------------------- 23.1/72.0 MB 16.4 MB/s eta 0:00:03\n",
      "     ------------ -------------------------- 23.1/72.0 MB 16.4 MB/s eta 0:00:03\n",
      "     ------------ -------------------------- 23.1/72.0 MB 16.4 MB/s eta 0:00:03\n",
      "     ------------ -------------------------- 23.1/72.0 MB 16.4 MB/s eta 0:00:03\n",
      "     ------------- ------------------------- 25.2/72.0 MB 11.7 MB/s eta 0:00:04\n",
      "     ------------- ------------------------- 25.5/72.0 MB 11.5 MB/s eta 0:00:05\n",
      "     -------------- ------------------------ 26.8/72.0 MB 15.6 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 27.8/72.0 MB 14.9 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 29.1/72.0 MB 15.6 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 29.5/72.0 MB 15.6 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 29.5/72.0 MB 15.6 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 29.5/72.0 MB 15.6 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 29.5/72.0 MB 15.6 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 29.5/72.0 MB 15.6 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 29.5/72.0 MB 15.6 MB/s eta 0:00:03\n",
      "     ---------------- ---------------------- 31.2/72.0 MB 11.1 MB/s eta 0:00:04\n",
      "     ----------------- --------------------- 32.1/72.0 MB 10.9 MB/s eta 0:00:04\n",
      "     ----------------- --------------------- 32.3/72.0 MB 10.6 MB/s eta 0:00:04\n",
      "     ------------------ -------------------- 34.3/72.0 MB 14.6 MB/s eta 0:00:03\n",
      "     ------------------ -------------------- 34.9/72.0 MB 14.2 MB/s eta 0:00:03\n",
      "     ------------------ -------------------- 34.9/72.0 MB 14.2 MB/s eta 0:00:03\n",
      "     ------------------ -------------------- 34.9/72.0 MB 14.2 MB/s eta 0:00:03\n",
      "     ------------------ -------------------- 34.9/72.0 MB 14.2 MB/s eta 0:00:03\n",
      "     ------------------- ------------------- 35.8/72.0 MB 12.6 MB/s eta 0:00:03\n",
      "     ------------------- ------------------- 35.8/72.0 MB 12.6 MB/s eta 0:00:03\n",
      "     ------------------- ------------------- 36.4/72.0 MB 11.7 MB/s eta 0:00:04\n",
      "     ------------------- ------------------- 36.9/72.0 MB 10.7 MB/s eta 0:00:04\n",
      "     -------------------- ------------------ 37.6/72.0 MB 10.9 MB/s eta 0:00:04\n",
      "     -------------------- ------------------ 38.6/72.0 MB 10.6 MB/s eta 0:00:04\n",
      "     --------------------- ----------------- 39.7/72.0 MB 10.6 MB/s eta 0:00:04\n",
      "     --------------------- ----------------- 39.9/72.0 MB 14.9 MB/s eta 0:00:03\n",
      "     --------------------- ----------------- 39.9/72.0 MB 14.9 MB/s eta 0:00:03\n",
      "     --------------------- ----------------- 39.9/72.0 MB 14.9 MB/s eta 0:00:03\n",
      "     ---------------------- ---------------- 40.7/72.0 MB 12.1 MB/s eta 0:00:03\n",
      "     ---------------------- ---------------- 40.7/72.0 MB 12.1 MB/s eta 0:00:03\n",
      "     ---------------------- ---------------- 41.1/72.0 MB 11.1 MB/s eta 0:00:03\n",
      "     ---------------------- ---------------- 41.3/72.0 MB 10.4 MB/s eta 0:00:03\n",
      "     ---------------------- ---------------- 41.8/72.0 MB 10.4 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 42.3/72.0 MB 9.8 MB/s eta 0:00:04\n",
      "     ----------------------- --------------- 43.5/72.0 MB 10.2 MB/s eta 0:00:03\n",
      "     ------------------------ -------------- 45.0/72.0 MB 10.2 MB/s eta 0:00:03\n",
      "     ------------------------ -------------- 45.7/72.0 MB 12.1 MB/s eta 0:00:03\n",
      "     ------------------------ -------------- 45.7/72.0 MB 12.1 MB/s eta 0:00:03\n",
      "     ------------------------ -------------- 45.7/72.0 MB 12.1 MB/s eta 0:00:03\n",
      "     ------------------------- ------------- 46.3/72.0 MB 10.7 MB/s eta 0:00:03\n",
      "     ------------------------- ------------- 46.5/72.0 MB 10.7 MB/s eta 0:00:03\n",
      "     ------------------------- ------------- 47.0/72.0 MB 10.4 MB/s eta 0:00:03\n",
      "     ------------------------- ------------- 47.4/72.0 MB 10.2 MB/s eta 0:00:03\n",
      "     -------------------------- ------------ 48.2/72.0 MB 10.4 MB/s eta 0:00:03\n",
      "     -------------------------- ------------ 48.9/72.0 MB 10.1 MB/s eta 0:00:03\n",
      "     --------------------------- ----------- 50.4/72.0 MB 11.7 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 50.4/72.0 MB 11.7 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 50.4/72.0 MB 11.7 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 51.0/72.0 MB 10.9 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 51.2/72.0 MB 10.9 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 51.6/72.0 MB 10.7 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 51.6/72.0 MB 10.7 MB/s eta 0:00:02\n",
      "     ---------------------------- ---------- 52.4/72.0 MB 10.7 MB/s eta 0:00:02\n",
      "     ---------------------------- ---------- 52.8/72.0 MB 10.1 MB/s eta 0:00:02\n",
      "     ----------------------------- --------- 54.2/72.0 MB 10.4 MB/s eta 0:00:02\n",
      "     ----------------------------- --------- 55.0/72.0 MB 10.1 MB/s eta 0:00:02\n",
      "     ------------------------------ -------- 56.6/72.0 MB 12.1 MB/s eta 0:00:02\n",
      "     ------------------------------ -------- 56.6/72.0 MB 12.1 MB/s eta 0:00:02\n",
      "     ------------------------------ -------- 56.6/72.0 MB 12.1 MB/s eta 0:00:02\n",
      "     ------------------------------ -------- 56.6/72.0 MB 12.1 MB/s eta 0:00:02\n",
      "     ------------------------------ -------- 56.6/72.0 MB 12.1 MB/s eta 0:00:02\n",
      "     ------------------------------ -------- 56.6/72.0 MB 12.1 MB/s eta 0:00:02\n",
      "     ------------------------------ -------- 56.6/72.0 MB 12.1 MB/s eta 0:00:02\n",
      "     ------------------------------- ------- 58.1/72.0 MB 10.2 MB/s eta 0:00:02\n",
      "     ------------------------------- ------- 59.0/72.0 MB 10.7 MB/s eta 0:00:02\n",
      "     -------------------------------- ------ 59.6/72.0 MB 10.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ----- 61.0/72.0 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 61.7/72.0 MB 12.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 62.1/72.0 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 62.1/72.0 MB 13.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 62.1/72.0 MB 13.6 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 62.7/72.0 MB 12.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 62.9/72.0 MB 11.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 63.1/72.0 MB 11.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 63.9/72.0 MB 10.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 63.9/72.0 MB 10.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 65.3/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 65.7/72.0 MB 9.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 67.5/72.0 MB 13.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 67.8/72.0 MB 13.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 67.8/72.0 MB 13.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 68.5/72.0 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 68.7/72.0 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 69.0/72.0 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 69.6/72.0 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 70.0/72.0 MB 10.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  70.9/72.0 MB 9.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  72.0/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  72.0/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  72.0/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  72.0/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  72.0/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  72.0/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  72.0/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  72.0/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  72.0/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  72.0/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  72.0/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  72.0/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  72.0/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  72.0/72.0 MB 10.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 72.0/72.0 MB 6.1 MB/s eta 0:00:00\n",
      "Collecting httpx (from paddlepaddle)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a2/65/6940eeb21dcb2953778a6895281c179efd9100463ff08cb6232bb6480da7/httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "Collecting numpy>=1.13 (from paddlepaddle)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/69/65/0d47953afa0ad569d12de5f65d964321c208492064c38fe3b0b9744f8d44/numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "     ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 1.4/14.9 MB 28.8 MB/s eta 0:00:01\n",
      "     ------- -------------------------------- 2.9/14.9 MB 30.3 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 4.6/14.9 MB 32.8 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 5.6/14.9 MB 29.6 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 5.9/14.9 MB 31.4 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 5.9/14.9 MB 31.4 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 5.9/14.9 MB 31.4 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 6.7/14.9 MB 18.6 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 6.7/14.9 MB 18.6 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 7.0/14.9 MB 16.0 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 7.1/14.9 MB 13.7 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 7.9/14.9 MB 14.9 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 8.4/14.9 MB 13.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 9.8/14.9 MB 15.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 11.0/14.9 MB 15.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 12.5/14.9 MB 15.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 12.5/14.9 MB 15.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 12.5/14.9 MB 15.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 12.5/14.9 MB 15.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 13.7/14.9 MB 12.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 13.7/14.9 MB 12.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 14.3/14.9 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 14.4/14.9 MB 10.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  14.9/14.9 MB 10.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  14.9/14.9 MB 10.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  14.9/14.9 MB 10.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 14.9/14.9 MB 9.2 MB/s eta 0:00:00\n",
      "Collecting Pillow (from paddlepaddle)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b8/da/ce52661f951562cbef4dad2809f2ade9e04e7ebc0afa86ec402a8bc89225/Pillow-10.1.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "     ------------------------ --------------- 1.6/2.6 MB 33.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.6/2.6 MB 33.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.6/2.6 MB 23.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: decorator in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddlepaddle) (5.1.1)\n",
      "Collecting astor (from paddlepaddle)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting opt-einsum==3.3.0 (from paddlepaddle)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting protobuf<=3.20.2,>=3.1.0 (from paddlepaddle)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/36/d8/8dac1b82e612464d062ad3d46f4ba6a97786bebeb2e16830ac5cb0d8ef8c/protobuf-3.20.2-cp38-cp38-win_amd64.whl (904 kB)\n",
      "     ---------------------------------------- 0.0/904.4 kB ? eta -:--:--\n",
      "     ------------------------------------- 904.4/904.4 kB 28.8 MB/s eta 0:00:00\n",
      "Collecting anyio (from httpx->paddlepaddle)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/85/4f/d010eca6914703d8e6be222165d02c3e708ed909cdb2b7af3743667f302e/anyio-4.1.0-py3-none-any.whl (83 kB)\n",
      "Collecting certifi (from httpx->paddlepaddle)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/64/62/428ef076be88fa93716b576e4a01f919d25968913e817077a386fcbe4f42/certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "Collecting httpcore==1.* (from httpx->paddlepaddle)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "Collecting idna (from httpx->paddlepaddle)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c2/e7/a82b05cf63a603df6e68d59ae6a68bf5064484a0718ea5033660af4b54a9/idna-3.6-py3-none-any.whl (61 kB)\n",
      "Collecting sniffio (from httpx->paddlepaddle)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c3/a0/5dba8ed157b0136607c7f2151db695885606968d1fae123dc3391e0cfdbf/sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->paddlepaddle)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio->httpx->paddlepaddle)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b8/9a/5028fd52db10e600f1c4674441b968cf2ea4959085bfb5b99fb1250e5f68/exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: sniffio, protobuf, Pillow, numpy, idna, h11, exceptiongroup, certifi, astor, opt-einsum, httpcore, anyio, httpx, paddlepaddle\n",
      "Successfully installed Pillow-10.1.0 anyio-4.1.0 astor-0.8.1 certifi-2023.11.17 exceptiongroup-1.2.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 idna-3.6 numpy-1.24.4 opt-einsum-3.3.0 paddlepaddle-2.5.2 protobuf-3.20.2 sniffio-1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\imank\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'C:\\Users\\imank\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script fleetrun.exe is installed in 'C:\\Users\\imank\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --user paddlepaddle -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19QCx1jOjIoq",
    "outputId": "2f3ec263-48a9-4a7e-c220-7ebc84cbe267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/fb/59/3eb58629e3749d9f4fc1e522487af369f9bd4c451f465d3054961fab6bf8/tensorflow-2.13.1-cp38-cp38-win_amd64.whl.metadata\n",
      "  Using cached tensorflow-2.13.1-cp38-cp38-win_amd64.whl.metadata (2.6 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/5b/6f/8b125d126d54061c0be610b135aaf2f8960f55c2e185ac32445e4a5012d5/tensorflow-2.13.0-cp38-cp38-win_amd64.whl.metadata\n",
      "  Using cached tensorflow-2.13.0-cp38-cp38-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-intel==2.13.0 from https://files.pythonhosted.org/packages/38/ba/dd4d998a852451e98dc009ecb208bbb0eeb0c8252dc35b7c4e1050762b36/tensorflow_intel-2.13.0-cp38-cp38-win_amd64.whl.metadata\n",
      "  Using cached tensorflow_intel-2.13.0-cp38-cp38-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
      "  Using cached absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for h5py>=2.9.0 from https://files.pythonhosted.org/packages/b5/f4/6047304e24c8ea459d8072c30ebc07e45081114f2f6c27b580e02854fd3a/h5py-3.10.0-cp38-cp38-win_amd64.whl.metadata\n",
      "  Using cached h5py-3.10.0-cp38-cp38-win_amd64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.25.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/21/8a/76a6b10fbc9180bbd922ccc8fb499e17d93fc71cadf3e502e29fc0e0e7e1/grpcio-1.59.3-cp38-cp38-win_amd64.whl.metadata\n",
      "  Using cached grpcio-1.59.3-cp38-cp38-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for keras<2.14,>=2.13.1 from https://files.pythonhosted.org/packages/2e/f3/19da7511b45e80216cbbd9467137b2d28919c58ba1ccb971435cb631e470/keras-2.13.1-py3-none-any.whl.metadata\n",
      "  Using cached keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/1f/eb/29123fbd92e4cb25d24713ab5d26ea74e02ce04290edc7c35356441de4f2/google_auth-2.25.1-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_auth-2.25.1-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/70/58/2c5a654173937d9f540a4971c569b44dcd55e5424a484d954cdaeebcf79c/Markdown-3.5.1-py3-none-any.whl.metadata\n",
      "  Using cached Markdown-3.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (7.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Using cached tensorflow-2.13.0-cp38-cp38-win_amd64.whl (1.9 kB)\n",
      "Using cached tensorflow_intel-2.13.0-cp38-cp38-win_amd64.whl (276.5 MB)\n",
      "Using cached absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "Using cached grpcio-1.59.3-cp38-cp38-win_amd64.whl (3.7 MB)\n",
      "Using cached h5py-3.10.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Using cached google_auth-2.25.1-py2.py3-none-any.whl (184 kB)\n",
      "Using cached Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "Installing collected packages: keras, h5py, grpcio, google-pasta, gast, astunparse, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 gast-0.4.0 google-auth-2.25.1 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.3 h5py-3.10.0 keras-2.13.1 markdown-3.5.1 requests-oauthlib-1.3.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-intel-2.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\imank\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script google-oauthlib-tool.exe is installed in 'C:\\Users\\imank\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\imank\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\imank\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (1.16.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (10.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install --user tensorflow\n",
    "%pip install --user pdf2image pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: img2table in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (1.2.5)\n",
      "Requirement already satisfied: polars[pandas]>=0.19.14 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from img2table) (0.19.19)\n",
      "Requirement already satisfied: pyarrow>=7 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from img2table) (14.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from img2table) (1.24.3)\n",
      "Requirement already satisfied: pymupdf>=1.19.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from img2table) (1.20.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from img2table) (4.6.0.66)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from img2table) (4.12.2)\n",
      "Requirement already satisfied: xlsxwriter>=3.0.6 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from img2table) (3.1.9)\n",
      "Requirement already satisfied: pandas in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from polars[pandas]>=0.19.14->img2table) (2.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from beautifulsoup4->img2table) (2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from pandas->polars[pandas]>=0.19.14->img2table) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from pandas->polars[pandas]>=0.19.14->img2table) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from pandas->polars[pandas]>=0.19.14->img2table) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->polars[pandas]>=0.19.14->img2table) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: img2table[paddle] in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (1.2.5)\n",
      "Requirement already satisfied: polars[pandas]>=0.19.14 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from img2table[paddle]) (0.19.19)\n",
      "Requirement already satisfied: pyarrow>=7 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from img2table[paddle]) (14.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from img2table[paddle]) (1.24.3)\n",
      "Requirement already satisfied: pymupdf>=1.19.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from img2table[paddle]) (1.20.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from img2table[paddle]) (4.6.0.66)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from img2table[paddle]) (4.12.2)\n",
      "Requirement already satisfied: xlsxwriter>=3.0.6 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from img2table[paddle]) (3.1.9)\n",
      "Requirement already satisfied: paddlepaddle in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from img2table[paddle]) (2.5.2)\n",
      "Requirement already satisfied: paddleocr>=2.0.6 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from img2table[paddle]) (2.7.0.3)\n",
      "Requirement already satisfied: shapely in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (2.0.2)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (0.21.0)\n",
      "Requirement already satisfied: imgaug in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (0.4.0)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (1.3.0.post5)\n",
      "Requirement already satisfied: lmdb in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (1.4.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (4.66.1)\n",
      "Requirement already satisfied: visualdl in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (2.5.3)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (3.5.2)\n",
      "Requirement already satisfied: opencv-contrib-python<=4.6.0.66 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (4.6.0.66)\n",
      "Requirement already satisfied: cython in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (3.0.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (4.9.3)\n",
      "Requirement already satisfied: premailer in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (3.10.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (3.1.2)\n",
      "Requirement already satisfied: attrdict in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (2.0.1)\n",
      "Requirement already satisfied: Pillow>=10.0.0 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (10.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (6.0.1)\n",
      "Requirement already satisfied: python-docx in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (1.1.0)\n",
      "Requirement already satisfied: fonttools>=4.24.0 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (4.46.0)\n",
      "Requirement already satisfied: fire>=0.3.0 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (0.5.0)\n",
      "Requirement already satisfied: pdf2docx in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddleocr>=2.0.6->img2table[paddle]) (0.5.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from polars[pandas]>=0.19.14->img2table[paddle]) (2.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from beautifulsoup4->img2table[paddle]) (2.5)\n",
      "Requirement already satisfied: httpx in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from paddlepaddle->img2table[paddle]) (0.25.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from paddlepaddle->img2table[paddle]) (5.1.1)\n",
      "Requirement already satisfied: astor in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from paddlepaddle->img2table[paddle]) (0.8.1)\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from paddlepaddle->img2table[paddle]) (3.3.0)\n",
      "Collecting protobuf<=3.20.2,>=3.1.0 (from paddlepaddle->img2table[paddle])\n",
      "  Using cached protobuf-3.20.2-cp38-cp38-win_amd64.whl (904 kB)\n",
      "Requirement already satisfied: six in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from fire>=0.3.0->paddleocr>=2.0.6->img2table[paddle]) (1.16.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from fire>=0.3.0->paddleocr>=2.0.6->img2table[paddle]) (2.4.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from httpx->paddlepaddle->img2table[paddle]) (4.1.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from httpx->paddlepaddle->img2table[paddle]) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from httpx->paddlepaddle->img2table[paddle]) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from httpx->paddlepaddle->img2table[paddle]) (3.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from httpx->paddlepaddle->img2table[paddle]) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from httpcore==1.*->httpx->paddlepaddle->img2table[paddle]) (0.14.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from imgaug->paddleocr>=2.0.6->img2table[paddle]) (1.10.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from imgaug->paddleocr>=2.0.6->img2table[paddle]) (3.7.4)\n",
      "Requirement already satisfied: imageio in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from imgaug->paddleocr>=2.0.6->img2table[paddle]) (2.33.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from scikit-image->paddleocr>=2.0.6->img2table[paddle]) (3.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from scikit-image->paddleocr>=2.0.6->img2table[paddle]) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from scikit-image->paddleocr>=2.0.6->img2table[paddle]) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from scikit-image->paddleocr>=2.0.6->img2table[paddle]) (23.2)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from scikit-image->paddleocr>=2.0.6->img2table[paddle]) (0.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from openpyxl->paddleocr>=2.0.6->img2table[paddle]) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from pandas->polars[pandas]>=0.19.14->img2table[paddle]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from pandas->polars[pandas]>=0.19.14->img2table[paddle]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from pandas->polars[pandas]>=0.19.14->img2table[paddle]) (2023.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from python-docx->paddleocr>=2.0.6->img2table[paddle]) (4.5.0)\n",
      "Requirement already satisfied: cssselect in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from premailer->paddleocr>=2.0.6->img2table[paddle]) (1.2.0)\n",
      "Requirement already satisfied: cssutils in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from premailer->paddleocr>=2.0.6->img2table[paddle]) (2.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from premailer->paddleocr>=2.0.6->img2table[paddle]) (2.31.0)\n",
      "Requirement already satisfied: cachetools in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from premailer->paddleocr>=2.0.6->img2table[paddle]) (5.3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from tqdm->paddleocr>=2.0.6->img2table[paddle]) (0.4.6)\n",
      "Requirement already satisfied: bce-python-sdk in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from visualdl->paddleocr>=2.0.6->img2table[paddle]) (0.8.97)\n",
      "Requirement already satisfied: flask>=1.1.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from visualdl->paddleocr>=2.0.6->img2table[paddle]) (3.0.0)\n",
      "Requirement already satisfied: Flask-Babel>=3.0.0 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from visualdl->paddleocr>=2.0.6->img2table[paddle]) (4.0.0)\n",
      "Requirement already satisfied: rarfile in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from visualdl->paddleocr>=2.0.6->img2table[paddle]) (4.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from visualdl->paddleocr>=2.0.6->img2table[paddle]) (5.9.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from flask>=1.1.1->visualdl->paddleocr>=2.0.6->img2table[paddle]) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from flask>=1.1.1->visualdl->paddleocr>=2.0.6->img2table[paddle]) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from flask>=1.1.1->visualdl->paddleocr>=2.0.6->img2table[paddle]) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from flask>=1.1.1->visualdl->paddleocr>=2.0.6->img2table[paddle]) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from flask>=1.1.1->visualdl->paddleocr>=2.0.6->img2table[paddle]) (1.7.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from flask>=1.1.1->visualdl->paddleocr>=2.0.6->img2table[paddle]) (7.0.0)\n",
      "Requirement already satisfied: Babel>=2.12 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from Flask-Babel>=3.0.0->visualdl->paddleocr>=2.0.6->img2table[paddle]) (2.13.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from anyio->httpx->paddlepaddle->img2table[paddle]) (1.2.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from bce-python-sdk->visualdl->paddleocr>=2.0.6->img2table[paddle]) (3.19.0)\n",
      "Requirement already satisfied: future>=0.6.0 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from bce-python-sdk->visualdl->paddleocr>=2.0.6->img2table[paddle]) (0.18.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from matplotlib->imgaug->paddleocr>=2.0.6->img2table[paddle]) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from matplotlib->imgaug->paddleocr>=2.0.6->img2table[paddle]) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from matplotlib->imgaug->paddleocr>=2.0.6->img2table[paddle]) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from matplotlib->imgaug->paddleocr>=2.0.6->img2table[paddle]) (3.1.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from matplotlib->imgaug->paddleocr>=2.0.6->img2table[paddle]) (6.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from requests->premailer->paddleocr>=2.0.6->img2table[paddle]) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from requests->premailer->paddleocr>=2.0.6->img2table[paddle]) (2.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from importlib-metadata>=3.6.0->flask>=1.1.1->visualdl->paddleocr>=2.0.6->img2table[paddle]) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from Jinja2>=3.1.2->flask>=1.1.1->visualdl->paddleocr>=2.0.6->img2table[paddle]) (2.1.3)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.1\n",
      "    Uninstalling protobuf-4.25.1:\n",
      "      Successfully uninstalled protobuf-4.25.1\n",
      "Successfully installed protobuf-3.20.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install --user img2table\n",
    "%pip install --user img2table[paddle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'PaddleOCR' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: paddleocr>=2.0.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (2.7.0.3)\n",
      "Collecting PyMuPDF==1.21.1\n",
      "  Downloading PyMuPDF-1.21.1-cp38-cp38-win_amd64.whl (11.7 MB)\n",
      "     ---------------------------------------- 0.0/11.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/11.7 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/11.7 MB 330.3 kB/s eta 0:00:36\n",
      "      --------------------------------------- 0.2/11.7 MB 1.5 MB/s eta 0:00:08\n",
      "     --- ------------------------------------ 1.0/11.7 MB 5.5 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.0/11.7 MB 5.5 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.0/11.7 MB 5.5 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.0/11.7 MB 5.5 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.0/11.7 MB 5.5 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.0/11.7 MB 4.5 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.7 MB 4.6 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.7 MB 4.6 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.7 MB 4.6 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.7 MB 4.6 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.1/11.7 MB 4.3 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.1/11.7 MB 4.3 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.1/11.7 MB 4.3 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.1/11.7 MB 4.3 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.1/11.7 MB 4.3 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.1/11.7 MB 4.3 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.1/11.7 MB 4.3 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.1/11.7 MB 4.3 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 3.9/11.7 MB 3.4 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.2/11.7 MB 3.7 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.2/11.7 MB 3.7 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.2/11.7 MB 3.7 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.2/11.7 MB 3.7 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.2/11.7 MB 3.7 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 4.7/11.7 MB 3.3 MB/s eta 0:00:03\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.5 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/11.7 MB 3.6 MB/s eta 0:00:02\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\http\\client.py\", line 459, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\http\\client.py\", line 503, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 248, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 92, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 546, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 397, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 173, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 156, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 206, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 293, in __init__\n",
      "    super().__init__(\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 225, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 304, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 538, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 609, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 166, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 107, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 147, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 587, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\contextlib.py\", line 131, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"c:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PaddlePaddle/PaddleOCR.git\n",
    "%pip install --user \"paddleocr>=2.0.1\" --upgrade PyMuPDF==1.21.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user paddleocr --upgrade\n",
    "# !pip install --user paddlepaddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download layoutparser and poppler(download release.zip) using this link\n",
    "#https://paddleocr.bj.bcebos.com/whl/layoutparser-0.0.0-py3-none-any.whl\n",
    "#https://github.com/oschwartz10612/poppler-windows/releases/\n",
    "# https://github.com/UB-Mannheim/tesseract/wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zCNHWuTDlduO",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\imank\\layoutparser-0.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from layoutparser==0.0.0) (1.24.4)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from layoutparser==0.0.0) (4.6.0.66)\n",
      "Requirement already satisfied: pandas in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from layoutparser==0.0.0) (2.0.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\imank\\appdata\\roaming\\python\\python38\\site-packages (from layoutparser==0.0.0) (10.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from layoutparser==0.0.0) (6.0.1)\n",
      "Collecting iopath (from layoutparser==0.0.0)\n",
      "  Using cached iopath-0.1.10.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tqdm in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from layoutparser==0.0.0) (4.66.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from iopath->layoutparser==0.0.0) (4.8.0)\n",
      "Collecting portalocker (from iopath->layoutparser==0.0.0)\n",
      "  Obtaining dependency information for portalocker from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from pandas->layoutparser==0.0.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from pandas->layoutparser==0.0.0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from pandas->layoutparser==0.0.0) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from tqdm->layoutparser==0.0.0) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->layoutparser==0.0.0) (1.16.0)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\imank\\.conda\\envs\\14-django_level_one\\lib\\site-packages (from portalocker->iopath->layoutparser==0.0.0) (227)\n",
      "Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Building wheels for collected packages: iopath\n",
      "  Building wheel for iopath (setup.py): started\n",
      "  Building wheel for iopath (setup.py): finished with status 'done'\n",
      "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31542 sha256=df65db4ef6c57de43ab669bef8d64f00f29ff0793bf22b490fb5a2f2e3fa2c27\n",
      "  Stored in directory: c:\\users\\imank\\appdata\\local\\pip\\cache\\wheels\\89\\3e\\24\\0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
      "Successfully built iopath\n",
      "Installing collected packages: portalocker, iopath, layoutparser\n",
      "Successfully installed iopath-0.1.10 layoutparser-0.0.0 portalocker-2.8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user -U layoutparser-0.0.0-py3-none-any.whl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install --user paddlepaddle-gpu==2.4.1.post112 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf==3.20.0\n",
      "  Using cached protobuf-3.20.0-cp39-cp39-win_amd64.whl (904 kB)\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-3.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "#if error no paddleOCR\n",
    "# %pip install --user protobuf==3.20.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pc-O8JVYWoNq"
   },
   "source": [
    "# **Image Conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "R-QDCDFYEyZk"
   },
   "outputs": [],
   "source": [
    "import layoutparser as lp\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qJo2RxvFEWTU"
   },
   "outputs": [],
   "source": [
    "#If error setup path and restart IDE\n",
    "pdf_path ='D:/Chrome Download/Material Table PDF/ASME II (1995) Table 2A.pdf'\n",
    "images = convert_from_path(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPdIcfS3EoTn",
    "outputId": "f30b052b-32b2-4581-8831-de6798962a1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file pages already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7_G2rCtX2Ivd"
   },
   "outputs": [],
   "source": [
    "for i in range(len(images)):\n",
    "    images[i].save('pages/page'+str(i+1)+'.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJkfIKYoRYmA"
   },
   "source": [
    "## **Image Processing for Scanned Pdf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uAgP1_CKRdf5"
   },
   "outputs": [],
   "source": [
    "\n",
    "output_directory = 'bright'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "input_directory = 'pages'\n",
    "brightness_factor = 1.5\n",
    "\n",
    "image_files = [file for file in os.listdir(input_directory) if file.lower().endswith(('.jpg', '.jpeg'))]\n",
    "\n",
    "for image_file in image_files:\n",
    "    img_path = os.path.join(input_directory, image_file)\n",
    "\n",
    "    # Open the image\n",
    "    im = Image.open(img_path)\n",
    "\n",
    "    # Enhance brightness\n",
    "    enhancer = ImageEnhance.Brightness(im)\n",
    "    im_output = enhancer.enhance(brightness_factor)\n",
    "\n",
    "    # Convert to grayscale (optional, depending on your image)\n",
    "    im_output = ImageOps.grayscale(im_output)\n",
    "\n",
    "    # Apply bilateral filter for denoising\n",
    "    im_output = im_output.filter(ImageFilter.UnsharpMask(radius=2, percent=150))\n",
    "\n",
    "    # Increase contrast to make text more visible\n",
    "    contrast = ImageEnhance.Contrast(im_output)\n",
    "    im_output = contrast.enhance(1.5)  # Adjust the factor as needed\n",
    "\n",
    "    # Save the processed image\n",
    "    output_path = os.path.join(output_directory, 'processed_' + image_file)\n",
    "    im_output.save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRbHEC5FF7uO",
    "outputId": "476d14b4-5603-4f29-c498-f97a6feac1f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'processed_page1.jpg' has been saved to the 'user' folder.\n",
      "'processed_page2.jpg' has been saved to the 'user' folder.\n",
      "'processed_page3.jpg' has been saved to the 'user' folder.\n"
     ]
    }
   ],
   "source": [
    "# Define the input directory\n",
    "input_directory = 'bright'\n",
    "\n",
    "# Ask the user to enter the page numbers they want to save\n",
    "page_selection_input = input(\"Enter the page numbers you want to process (e.g., 1-5, 6-10): \")\n",
    "\n",
    "# Create a 'user' folder if it doesn't exist\n",
    "user_folder = 'user'\n",
    "os.makedirs(user_folder, exist_ok=True)\n",
    "\n",
    "# Get a list of files in the input directory\n",
    "file_list = os.listdir(input_directory)\n",
    "\n",
    "def parse_page_selection(page_selection):\n",
    "    parts = page_selection.split('-')\n",
    "    if len(parts) == 1:\n",
    "        # Single page\n",
    "        page_number = int(parts[0])\n",
    "        return [page_number]\n",
    "    elif len(parts) == 2:\n",
    "        # Page range\n",
    "        start_page = int(parts[0])\n",
    "        end_page = int(parts[1])\n",
    "        return list(range(start_page, end_page + 1))\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Split the user input by commas and process each part\n",
    "page_selections = page_selection_input.split(',')\n",
    "\n",
    "for page_selection in page_selections:\n",
    "    page_numbers = parse_page_selection(page_selection)\n",
    "    for page_number in page_numbers:\n",
    "        if 1 <= page_number <= len(file_list):\n",
    "            selected_page = f'processed_page{page_number}.jpg'\n",
    "            source_path = os.path.join(input_directory, selected_page)\n",
    "            destination_path = os.path.join(user_folder, selected_page)\n",
    "\n",
    "            img = cv2.imread(source_path)\n",
    "            cv2.imwrite(destination_path, img)\n",
    "            print(f\"'{selected_page}' has been saved to the 'user' folder.\")\n",
    "        else:\n",
    "            print(f\"Invalid page number: {page_number}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nEjE07YIHYNa",
    "outputId": "cb84aed8-9b91-461c-c05e-a1bd8b8a7479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user has been emptied.\n"
     ]
    }
   ],
   "source": [
    "#CLEAR USER FOLDER\n",
    "# import os\n",
    "\n",
    "# user_folder = 'user'\n",
    "\n",
    "# def empty_user_folder(folder):\n",
    "#     if os.path.exists(folder):\n",
    "#         for file in os.listdir(folder):\n",
    "#             file_path = os.path.join(folder, file)\n",
    "#             try:\n",
    "#                 if os.path.isfile(file_path):\n",
    "#                     os.unlink(file_path)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error: {e}\")\n",
    "#         print(f\"{folder} has been emptied.\")\n",
    "#     else:\n",
    "#         print(f\"{folder} does not exist.\")\n",
    "\n",
    "# empty_user_folder(user_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZ-dzUMDqGSq",
    "outputId": "aad62695-cf74-44b3-d3ac-d7dfd926f624"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlsx has been emptied.\n"
     ]
    }
   ],
   "source": [
    "##CLEAR xlsx FOLDER\n",
    "# import os\n",
    "\n",
    "# user_folder = 'xlsx'\n",
    "\n",
    "# def empty_user_folder(folder):\n",
    "#     if os.path.exists(folder):\n",
    "#         for file in os.listdir(folder):\n",
    "#             file_path = os.path.join(folder, file)\n",
    "#             try:\n",
    "#                 if os.path.isfile(file_path):\n",
    "#                     os.unlink(file_path)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error: {e}\")\n",
    "#         print(f\"{folder} has been emptied.\")\n",
    "#     else:\n",
    "#         print(f\"{folder} does not exist.\")\n",
    "\n",
    "# empty_user_folder(user_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rnktZLtWxJr"
   },
   "source": [
    "# **System Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with rectangles saved to c:\\Users\\imank\\cells\\cells_cropped_page1.jpg_1.jpg\n",
      "Table data for cropped_page1.jpg_1.xlsx saved to c:\\Users\\imank\\xlsx\\cropped_page1.jpg_1.xlsx\n",
      "Image with rectangles saved to c:\\Users\\imank\\cells\\cells_cropped_page2.jpg_2.jpg\n",
      "Table data for cropped_page2.jpg_2.xlsx saved to c:\\Users\\imank\\xlsx\\cropped_page2.jpg_2.xlsx\n",
      "Image with rectangles saved to c:\\Users\\imank\\cells\\cells_cropped_page3.jpg_3.jpg\n",
      "Table data for cropped_page3.jpg_3.xlsx saved to c:\\Users\\imank\\xlsx\\cropped_page3.jpg_3.xlsx\n"
     ]
    }
   ],
   "source": [
    "##PytesseractLast\n",
    "from img2table.ocr import TesseractOCR\n",
    "import cv2\n",
    "from img2table.document import Image\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "import layoutparser as lp\n",
    "from layoutparser.models import PaddleDetectionLayoutModel\n",
    "\n",
    "# Define the directories\n",
    "directories = ['detection', 'xlsx', 'cells', 'cropped']\n",
    "\n",
    "# Create the directories\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Now, you can use these directories in your code like this:\n",
    "cropped_dir = os.path.join(os.getcwd(), 'cropped')\n",
    "detection_dir = os.path.join(os.getcwd(), 'detection')\n",
    "xlsx_dir = os.path.join(os.getcwd(), 'xlsx')\n",
    "cells_dir = os.path.join(os.getcwd(), 'cells')\n",
    "\n",
    "def detect_tables(image_directory, layout_model):\n",
    "    #padding gap table    \n",
    "    padding = 10 \n",
    "\n",
    "    # Initialize a counter for the cropped tables\n",
    "    counter = 1\n",
    "\n",
    "    all_table_boxes = []\n",
    "\n",
    "    for filename in os.listdir(image_directory):\n",
    "        try:\n",
    "            # Construct the image file path\n",
    "            image_path = os.path.join(image_directory, filename)\n",
    "            \n",
    "            # Check if the file is an image (you can improve this check if needed)\n",
    "            if not image_path.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                continue\n",
    "            \n",
    "            # Load image\n",
    "            image = cv2.imread(image_path)\n",
    "            image = image[..., ::-1]  # Convert BGR to RGB\n",
    "\n",
    "            # Extract page number from filename\n",
    "            page_number = filename.split('_')[-1].split('.')[0] \n",
    "            # Detect layout\n",
    "            layout = layout_model.detect(image)\n",
    "\n",
    "            # Extract page number from filename\n",
    "            page_number = filename.split('_')[1] if '_' in filename else ''\n",
    "\n",
    "            table_boxes = []\n",
    "\n",
    "            for l in layout:\n",
    "                if l.type == 'Table':\n",
    "                    x1 = int(l.block.x_1)\n",
    "                    y1 = int(l.block.y_1)\n",
    "                    x2 = int(l.block.x_2)\n",
    "                    y2 = int(l.block.y_2)\n",
    "\n",
    "                    # Crop the table from the image with padding\n",
    "                    cropped_image = image[max(0, y1 - padding):min(image.shape[0], y2 + padding),\n",
    "                                          max(0, x1 - padding):min(image.shape[1], x2 + padding)]\n",
    "\n",
    "                    # Save the cropped table in the 'layoutdetection' folder\n",
    "                    cropped_filename = os.path.join(cropped_dir, f'cropped_{page_number}_{counter}.jpg')\n",
    "                    cv2.imwrite(cropped_filename, cropped_image)\n",
    "\n",
    "                    counter += 1\n",
    "                    table_boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "            all_table_boxes.extend(table_boxes)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "\n",
    "    return all_table_boxes\n",
    "        \n",
    "def process_images(image_directory):\n",
    "    # Check if the specified folder exists\n",
    "    if not os.path.exists(image_directory) or not os.path.isdir(image_directory):\n",
    "        print(f\"Error: The specified directory '{image_directory}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Initialize TesseractOCR with user-defined parameters\n",
    "    tesseract_ocr = TesseractOCR(\n",
    "        n_threads=1,\n",
    "        lang=\"eng\",\n",
    "        psm=6\n",
    "    )\n",
    "\n",
    "    # Process each image in the directory\n",
    "    for filename in os.listdir(image_directory):\n",
    "        try:\n",
    "            # Construct the image file path\n",
    "            img_path = os.path.join(image_directory, filename)\n",
    "\n",
    "            # Check if the file is an image (you can improve this check if needed)\n",
    "            if not img_path.lower().endswith(('.jpg')):\n",
    "                continue\n",
    "\n",
    "            # Define the image\n",
    "            img = Image(src=img_path)\n",
    "\n",
    "            # Extract tables using img2table\n",
    "            extracted_tables = img.extract_tables(\n",
    "                ocr=tesseract_ocr,\n",
    "                implicit_rows=True,\n",
    "                borderless_tables=True,\n",
    "                min_confidence=50\n",
    "            )\n",
    "            # Load the image for visualization\n",
    "            table_img = cv2.imread(img_path)\n",
    "\n",
    "            # Draw rectangles around the extracted table cells\n",
    "            for table in extracted_tables:\n",
    "                for row in table.content.values():\n",
    "                    for cell in row:\n",
    "                        cv2.rectangle(table_img, (cell.bbox.x1, cell.bbox.y1), (cell.bbox.x2, cell.bbox.y2), (255, 0, 0), 2)\n",
    "            # Save the image with rectangles\n",
    "            output_image_path = os.path.join(cells_dir, f\"cells_{filename}\")\n",
    "            cv2.imwrite(output_image_path, table_img)\n",
    "            print(f\"Image with rectangles saved to {output_image_path}\")\n",
    "\n",
    "            # Display the image with rectangles\n",
    "            # PILImage.fromarray(table_img).show()\n",
    "\n",
    "            # Convert the extracted table to an Excel file\n",
    "            filename_without_ext = os.path.splitext(filename)[0]\n",
    "            output_path = os.path.join(xlsx_dir, f\"{filename_without_ext}.xlsx\")\n",
    "            img.to_xlsx(output_path, implicit_rows=True, borderless_tables=True, ocr=tesseract_ocr)\n",
    "\n",
    "            print(f\"Table data for {filename_without_ext}.xlsx saved to {output_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "layout_model = PaddleDetectionLayoutModel(\n",
    "    \n",
    "    config_path=\"lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config\",\n",
    "    threshold=0.2,\n",
    "    label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"},\n",
    "    enforce_cpu=True,\n",
    "    enable_mkldnn=True\n",
    ")\n",
    "\n",
    "#MAIN\n",
    "user_folder_path = os.path.join(os.getcwd(), 'user')\n",
    "detect_tables (user_folder_path, layout_model)  \n",
    "process_images(cropped_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image with rectangles saved to c:\\Users\\imank\\cells\\cells_cropped_page1.jpg\n",
      "Table data for cropped_page1_1.jpg saved to c:\\Users\\imank\\xlsx\\table_cropped_page1.xlsx\n",
      "Image with rectangles saved to c:\\Users\\imank\\cells\\cells_cropped_page2.jpg\n",
      "Table data for cropped_page2_1.jpg saved to c:\\Users\\imank\\xlsx\\table_cropped_page2.xlsx\n",
      "Image with rectangles saved to c:\\Users\\imank\\cells\\cells_cropped_page3.jpg\n",
      "Table data for cropped_page3_1.jpg saved to c:\\Users\\imank\\xlsx\\table_cropped_page3.xlsx\n"
     ]
    }
   ],
   "source": [
    "##PaddleOCRLAST\n",
    "from img2table.ocr import PaddleOCR\n",
    "import cv2\n",
    "from img2table.document import Image\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "from layoutparser.models import PaddleDetectionLayoutModel\n",
    "\n",
    "# Define the directories\n",
    "directories = ['detection', 'xlsx', 'cells', 'cropped']\n",
    "\n",
    "# Create the directories\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Now, you can use these directories in your code like this:\n",
    "cropped_dir = os.path.join(os.getcwd(), 'cropped')\n",
    "detection_dir = os.path.join(os.getcwd(), 'detection')\n",
    "xlsx_dir = os.path.join(os.getcwd(), 'xlsx')\n",
    "cells_dir = os.path.join(os.getcwd(), 'cells')\n",
    "\n",
    "def detect_tables(image_directory, layout_model):\n",
    "    #padding gap table    \n",
    "    padding = 5 \n",
    "\n",
    "    all_table_boxes = []\n",
    "\n",
    "    for filename in os.listdir(image_directory):\n",
    "        # Initialize a counter for the cropped tables\n",
    "        counter = 1\n",
    "\n",
    "        try:\n",
    "            # Construct the image file path\n",
    "            image_path = os.path.join(image_directory, filename)\n",
    "            \n",
    "            # Check if the file is an image (you can improve this check if needed)\n",
    "            if not image_path.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                continue\n",
    "            \n",
    "            # Load image\n",
    "            image = cv2.imread(image_path)\n",
    "            image = image[..., ::-1]  # Convert BGR to RGB\n",
    "\n",
    "            # Detect layout\n",
    "            layout = layout_model.detect(image)\n",
    "\n",
    "            # Extract page number from filename\n",
    "            page_number = filename.split('_')[-1].split('.')[0]\n",
    "\n",
    "            table_boxes = []\n",
    "\n",
    "            for l in layout:\n",
    "                if l.type == 'Table':\n",
    "                    x1 = int(l.block.x_1)\n",
    "                    y1 = int(l.block.y_1)\n",
    "                    x2 = int(l.block.x_2)\n",
    "                    y2 = int(l.block.y_2)\n",
    "\n",
    "                    # Crop the table from the image with padding\n",
    "                    cropped_image = image[max(0, y1 - padding):min(image.shape[0], y2 + padding),\n",
    "                                          max(0, x1 - padding):min(image.shape[1], x2 + padding)]\n",
    "\n",
    "                    # Check if the filename already contains the \".jpg\" extension\n",
    "                    cropped_filename = os.path.join(cropped_dir, f'cropped_{page_number}_{counter}.jpg')\n",
    "                    cv2.imwrite(cropped_filename, cropped_image)\n",
    "\n",
    "                    counter += 1\n",
    "                    table_boxes.append([x1, y1, x2, y2])\n",
    "            all_table_boxes.extend(table_boxes)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "\n",
    "    return all_table_boxes\n",
    "def process_images(image_directory):\n",
    "    # Check if the specified folder exists\n",
    "    if not os.path.exists(image_directory) or not os.path.isdir(image_directory):\n",
    "        print(f\"Error: The specified directory '{image_directory}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    os.environ['PADDLEOCR_MODELS'] = '/Users/user/Downloads/PaddleOCR'\n",
    "    os.environ['PADDLEOCR_REC_MODEL_DIR'] = 'PaddleOCR/inference/en_PP-OCRv4_rec'\n",
    "    os.environ['PADDLEOCR_DET_MODEL_DIR'] = 'PaddleOCR/output/det_db_inference'\n",
    "    # Initialize TesseractOCR with user-defined parameters\n",
    "    paddle_ocr = PaddleOCR(lang=\"en\")\n",
    "    # paddle_ocr = PaddleOCR(lang=\"en\", kw={\"use_dilation\": True})\n",
    "\n",
    "    # Process each image in the directory\n",
    "    for filename in os.listdir(image_directory):\n",
    "        try:\n",
    "            # Construct the image file path\n",
    "            img_path = os.path.join(image_directory, filename)\n",
    "\n",
    "            # Check if the file is an image (you can improve this check if needed)\n",
    "            if not img_path.lower().endswith(('.jpg')):\n",
    "                continue\n",
    "\n",
    "            # Define the image\n",
    "            img = Image(src=img_path)\n",
    "\n",
    "            # Extract tables using img2table\n",
    "            extracted_tables = img.extract_tables(\n",
    "                ocr=paddle_ocr,\n",
    "                implicit_rows=False,\n",
    "                borderless_tables=True,\n",
    "                min_confidence=50\n",
    "            )\n",
    "\n",
    "            # Load the image for visualization\n",
    "            table_img = cv2.imread(img_path)\n",
    "\n",
    "            # Draw rectangles around the extracted table cells\n",
    "            for table in extracted_tables:\n",
    "                for row in table.content.values():\n",
    "                    for cell in row:\n",
    "                        cv2.rectangle(table_img, (cell.bbox.x1, cell.bbox.y1), (cell.bbox.x2, cell.bbox.y2), (255, 0, 0), 2)\n",
    "\n",
    "            # Remove the counter from the filename\n",
    "            filename_without_counter = filename.rsplit('_', 1)[0]\n",
    "\n",
    "            # Save the image with rectangles\n",
    "            output_image_path = os.path.join(cells_dir, f\"cells_{filename_without_counter}.jpg\")\n",
    "            cv2.imwrite(output_image_path, table_img)\n",
    "            print(f\"Image with rectangles saved to {output_image_path}\")\n",
    "\n",
    "            # Convert the extracted table to an Excel file\n",
    "            output_filename = f\"table_{filename_without_counter}.xlsx\"\n",
    "            output_path = os.path.join(xlsx_dir, output_filename)\n",
    "\n",
    "            img.to_xlsx(output_path, implicit_rows=True, borderless_tables=True, ocr=paddle_ocr)\n",
    "\n",
    "            print(f\"Table data for {filename} saved to {output_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "layout_model = PaddleDetectionLayoutModel(\n",
    "    \n",
    "    config_path=\"lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config\",\n",
    "    threshold=0.2,\n",
    "    label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"},\n",
    "    enforce_cpu=True,\n",
    "    enable_mkldnn=True\n",
    ")\n",
    "\n",
    "#MAIN\n",
    "user_folder_path = os.path.join(os.getcwd(), 'user')\n",
    "detect_tables (user_folder_path, layout_model)  \n",
    "process_images(cropped_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table detection saved as c:\\Users\\imank\\cropped\\table_page1.jpg_1.jpg\n",
      "Table detection saved as c:\\Users\\imank\\cropped\\table_page2.jpg_2.jpg\n",
      "Table detection saved as c:\\Users\\imank\\cropped\\table_page3.jpg_3.jpg\n",
      "Image with rectangles saved to c:\\Users\\imank\\cells\\table_image_table_page1.jpg_1.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\imank\\Task_UserInput(1).ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/imank/Task_UserInput%281%29.ipynb#X33sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m user_folder_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mgetcwd(), \u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/imank/Task_UserInput%281%29.ipynb#X33sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m detect_tables (user_folder_path, layout_model)  \n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/imank/Task_UserInput%281%29.ipynb#X33sZmlsZQ%3D%3D?line=155'>156</a>\u001b[0m process_images(cropped_dir)\n",
      "\u001b[1;32mc:\\Users\\imank\\Task_UserInput(1).ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/imank/Task_UserInput%281%29.ipynb#X33sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m     output_filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtable_\u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(filename)[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m.xlsx\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/imank/Task_UserInput%281%29.ipynb#X33sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m     output_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(xlsx_dir, output_filename)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/imank/Task_UserInput%281%29.ipynb#X33sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m     img\u001b[39m.\u001b[39;49mto_xlsx(output_path, implicit_rows\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, borderless_tables\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, ocr\u001b[39m=\u001b[39;49mpaddle_ocr)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/imank/Task_UserInput%281%29.ipynb#X33sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTable data for \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m saved to \u001b[39m\u001b[39m{\u001b[39;00moutput_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/imank/Task_UserInput%281%29.ipynb#X33sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\img2table\\document\\base\\__init__.py:151\u001b[0m, in \u001b[0;36mDocument.to_xlsx\u001b[1;34m(self, dest, ocr, implicit_rows, borderless_tables, min_confidence)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39mCreate xlsx file containing all extracted tables from document\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39m:param dest: destination for xlsx file\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[39m:return: if a buffer is passed as dest arg, it is returned containing xlsx data\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[39m# Extract tables\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m extracted_tables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_tables(ocr\u001b[39m=\u001b[39;49mocr,\n\u001b[0;32m    152\u001b[0m                                        implicit_rows\u001b[39m=\u001b[39;49mimplicit_rows,\n\u001b[0;32m    153\u001b[0m                                        borderless_tables\u001b[39m=\u001b[39;49mborderless_tables,\n\u001b[0;32m    154\u001b[0m                                        min_confidence\u001b[39m=\u001b[39;49mmin_confidence)\n\u001b[0;32m    155\u001b[0m extracted_tables \u001b[39m=\u001b[39m {\u001b[39m0\u001b[39m: extracted_tables} \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(extracted_tables, \u001b[39mlist\u001b[39m) \u001b[39melse\u001b[39;00m extracted_tables\n\u001b[0;32m    157\u001b[0m \u001b[39m# Create workbook\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\img2table\\document\\image.py:42\u001b[0m, in \u001b[0;36mImage.extract_tables\u001b[1;34m(self, ocr, implicit_rows, borderless_tables, min_confidence)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_tables\u001b[39m(\u001b[39mself\u001b[39m, ocr: \u001b[39m\"\u001b[39m\u001b[39mOCRInstance\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, implicit_rows: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, borderless_tables: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     33\u001b[0m                    min_confidence: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[ExtractedTable]:\n\u001b[0;32m     34\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m    Extract tables from document\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39m    :param ocr: OCRInstance object used to extract table content\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m    :return: list of extracted tables\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     extracted_tables \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Image, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mextract_tables(ocr\u001b[39m=\u001b[39;49mocr,\n\u001b[0;32m     43\u001b[0m                                                          implicit_rows\u001b[39m=\u001b[39;49mimplicit_rows,\n\u001b[0;32m     44\u001b[0m                                                          borderless_tables\u001b[39m=\u001b[39;49mborderless_tables,\n\u001b[0;32m     45\u001b[0m                                                          min_confidence\u001b[39m=\u001b[39;49mmin_confidence)\n\u001b[0;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m extracted_tables\u001b[39m.\u001b[39mget(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\img2table\\document\\base\\__init__.py:123\u001b[0m, in \u001b[0;36mDocument.extract_tables\u001b[1;34m(self, ocr, implicit_rows, borderless_tables, min_confidence)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39m# Extract tables from document\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimg2table\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtables\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m TableImage\n\u001b[1;32m--> 123\u001b[0m tables \u001b[39m=\u001b[39m {idx: TableImage(img\u001b[39m=\u001b[39mimg,\n\u001b[0;32m    124\u001b[0m                           min_confidence\u001b[39m=\u001b[39mmin_confidence)\u001b[39m.\u001b[39mextract_tables(implicit_rows\u001b[39m=\u001b[39mimplicit_rows,\n\u001b[0;32m    125\u001b[0m                                                                         borderless_tables\u001b[39m=\u001b[39mborderless_tables)\n\u001b[0;32m    126\u001b[0m           \u001b[39mfor\u001b[39;00m idx, img \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages)}\n\u001b[0;32m    128\u001b[0m \u001b[39m# Update table content with OCR if possible\u001b[39;00m\n\u001b[0;32m    129\u001b[0m tables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_table_content(tables\u001b[39m=\u001b[39mtables,\n\u001b[0;32m    130\u001b[0m                                 ocr\u001b[39m=\u001b[39mocr,\n\u001b[0;32m    131\u001b[0m                                 min_confidence\u001b[39m=\u001b[39mmin_confidence)\n",
      "File \u001b[1;32mc:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\img2table\\document\\base\\__init__.py:123\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39m# Extract tables from document\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimg2table\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtables\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m TableImage\n\u001b[1;32m--> 123\u001b[0m tables \u001b[39m=\u001b[39m {idx: TableImage(img\u001b[39m=\u001b[39;49mimg,\n\u001b[0;32m    124\u001b[0m                           min_confidence\u001b[39m=\u001b[39;49mmin_confidence)\u001b[39m.\u001b[39;49mextract_tables(implicit_rows\u001b[39m=\u001b[39;49mimplicit_rows,\n\u001b[0;32m    125\u001b[0m                                                                         borderless_tables\u001b[39m=\u001b[39;49mborderless_tables)\n\u001b[0;32m    126\u001b[0m           \u001b[39mfor\u001b[39;00m idx, img \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages)}\n\u001b[0;32m    128\u001b[0m \u001b[39m# Update table content with OCR if possible\u001b[39;00m\n\u001b[0;32m    129\u001b[0m tables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_table_content(tables\u001b[39m=\u001b[39mtables,\n\u001b[0;32m    130\u001b[0m                                 ocr\u001b[39m=\u001b[39mocr,\n\u001b[0;32m    131\u001b[0m                                 min_confidence\u001b[39m=\u001b[39mmin_confidence)\n",
      "File \u001b[1;32mc:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\img2table\\tables\\image.py:128\u001b[0m, in \u001b[0;36mTableImage.extract_tables\u001b[1;34m(self, implicit_rows, borderless_tables)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_bordered_tables(implicit_rows\u001b[39m=\u001b[39mimplicit_rows)\n\u001b[0;32m    126\u001b[0m \u001b[39mif\u001b[39;00m borderless_tables:\n\u001b[0;32m    127\u001b[0m     \u001b[39m# Extract borderless tables\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_borderless_tables()\n\u001b[0;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtables\n",
      "File \u001b[1;32mc:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\img2table\\tables\\image.py:106\u001b[0m, in \u001b[0;36mTableImage.extract_borderless_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39m# Median line separation needs to be not null to extract borderless tables\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmedian_line_sep \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     \u001b[39m# Extract borderless tables\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     borderless_tbs \u001b[39m=\u001b[39m identify_borderless_tables(thresh\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthresh,\n\u001b[0;32m    107\u001b[0m                                                 char_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchar_length,\n\u001b[0;32m    108\u001b[0m                                                 median_line_sep\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmedian_line_sep,\n\u001b[0;32m    109\u001b[0m                                                 lines\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlines,\n\u001b[0;32m    110\u001b[0m                                                 contours\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontours,\n\u001b[0;32m    111\u001b[0m                                                 existing_tables\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtables)\n\u001b[0;32m    113\u001b[0m     \u001b[39m# Add to tables\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtables \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [tb \u001b[39mfor\u001b[39;00m tb \u001b[39min\u001b[39;00m borderless_tbs \u001b[39mif\u001b[39;00m tb\u001b[39m.\u001b[39mnb_rows \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m tb\u001b[39m.\u001b[39mnb_columns \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\img2table\\tables\\processing\\borderless_tables\\__init__.py:50\u001b[0m, in \u001b[0;36midentify_borderless_tables\u001b[1;34m(thresh, lines, char_length, median_line_sep, contours, existing_tables)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mIdentify borderless tables in image\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m:param thresh: thresholded image array\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39m:return: list of detected borderless tables\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39m# Segment image and identify parts that can correspond to tables\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m table_segments \u001b[39m=\u001b[39m segment_image(thresh\u001b[39m=\u001b[39;49mthresh,\n\u001b[0;32m     51\u001b[0m                                lines\u001b[39m=\u001b[39;49mlines,\n\u001b[0;32m     52\u001b[0m                                char_length\u001b[39m=\u001b[39;49mchar_length,\n\u001b[0;32m     53\u001b[0m                                median_line_sep\u001b[39m=\u001b[39;49mmedian_line_sep)\n\u001b[0;32m     55\u001b[0m \u001b[39m# In each segment, create groups of rows and identify tables\u001b[39;00m\n\u001b[0;32m     56\u001b[0m tables \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\img2table\\tables\\processing\\borderless_tables\\layout\\__init__.py:23\u001b[0m, in \u001b[0;36msegment_image\u001b[1;34m(thresh, lines, char_length, median_line_sep)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mSegment image and its elements\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m:param thresh: thresholded image array\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39m:return: list of ImageSegment objects with corresponding elements\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m# Identify image elements\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m img_elements \u001b[39m=\u001b[39m get_image_elements(thresh\u001b[39m=\u001b[39;49mthresh,\n\u001b[0;32m     24\u001b[0m                                   lines\u001b[39m=\u001b[39;49mlines,\n\u001b[0;32m     25\u001b[0m                                   char_length\u001b[39m=\u001b[39;49mchar_length,\n\u001b[0;32m     26\u001b[0m                                   median_line_sep\u001b[39m=\u001b[39;49mmedian_line_sep)\n\u001b[0;32m     28\u001b[0m \u001b[39m# Identify column segments\u001b[39;00m\n\u001b[0;32m     29\u001b[0m y_min, y_max \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m([el\u001b[39m.\u001b[39my1 \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m img_elements]), \u001b[39mmax\u001b[39m([el\u001b[39m.\u001b[39my2 \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m img_elements])\n",
      "File \u001b[1;32mc:\\Users\\imank\\.conda\\envs\\14-Django_Level_One\\lib\\site-packages\\img2table\\tables\\processing\\borderless_tables\\layout\\image_elements.py:34\u001b[0m, in \u001b[0;36mget_image_elements\u001b[1;34m(thresh, lines, char_length, median_line_sep)\u001b[0m\n\u001b[0;32m     31\u001b[0m dilate \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mdilate(thresh, kernel, iterations\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[39m# Find contours, highlight text areas, and extract ROIs\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m cnts \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mfindContours(dilate, cv2\u001b[39m.\u001b[39;49mRETR_EXTERNAL, cv2\u001b[39m.\u001b[39;49mCHAIN_APPROX_SIMPLE)\n\u001b[0;32m     35\u001b[0m cnts \u001b[39m=\u001b[39m cnts[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cnts) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m cnts[\u001b[39m1\u001b[39m]\n\u001b[0;32m     37\u001b[0m \u001b[39m# Get list of contours\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##PaddleOCRtestforEnhance\n",
    "\n",
    "from img2table.ocr import PaddleOCR\n",
    "import cv2\n",
    "from img2table.document import Image\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "import layoutparser as lp\n",
    "from layoutparser.models import PaddleDetectionLayoutModel\n",
    "import layoutparser as lp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Define the directories\n",
    "directories = ['detection', 'xlsx', 'cells', 'cropped']\n",
    "\n",
    "# Create the directories\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Now, you can use these directories in your code like this:\n",
    "cropped_dir = os.path.join(os.getcwd(), 'cropped')\n",
    "detection_dir = os.path.join(os.getcwd(), 'detection')\n",
    "xlsx_dir = os.path.join(os.getcwd(), 'xlsx')\n",
    "cells_dir = os.path.join(os.getcwd(), 'cells')\n",
    "\n",
    "\n",
    "def detect_tables(image_directory, layout_model):\n",
    "    #padding gap table    \n",
    "    padding = 5 \n",
    "\n",
    "    # Initialize a counter for the cropped tables\n",
    "    counter = 1\n",
    "\n",
    "    all_table_boxes = []\n",
    "\n",
    "    for filename in os.listdir(image_directory):\n",
    "        try:\n",
    "            # Construct the image file path\n",
    "            image_path = os.path.join(image_directory, filename)\n",
    "            \n",
    "            # Check if the file is an image (you can improve this check if needed)\n",
    "            if not image_path.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                continue\n",
    "            \n",
    "            # Load image\n",
    "            image = cv2.imread(image_path)\n",
    "            image = image[..., ::-1]  # Convert BGR to RGB\n",
    "\n",
    "            # Detect layout\n",
    "            layout = layout_model.detect(image)\n",
    "\n",
    "            # Extract page number from filename\n",
    "            page_number = filename.split('_')[1] if '_' in filename else ''\n",
    "\n",
    "            table_boxes = []\n",
    "\n",
    "            for l in layout:\n",
    "                if l.type == 'Table':\n",
    "                    x1 = int(l.block.x_1)\n",
    "                    y1 = int(l.block.y_1)\n",
    "                    x2 = int(l.block.x_2)\n",
    "                    y2 = int(l.block.y_2)\n",
    "\n",
    "                    # Crop the table from the image with padding\n",
    "                    cropped_image = image[max(0, y1 - padding):min(image.shape[0], y2 + padding),\n",
    "                                          max(0, x1 - padding):min(image.shape[1], x2 + padding)]\n",
    "\n",
    "                    # Save the cropped table in the 'layoutdetection' folder\n",
    "                    cropped_filename = os.path.join(cropped_dir, f'table_{page_number}_{counter}.jpg')\n",
    "                    cv2.imwrite(cropped_filename, cropped_image)\n",
    "\n",
    "                    counter += 1\n",
    "                    table_boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "            print(f\"Table detection saved as {cropped_filename}\")\n",
    "            all_table_boxes.extend(table_boxes)\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "\n",
    "    return all_table_boxes\n",
    "        \n",
    "def process_images(image_directory):\n",
    "    # Check if the specified folder exists\n",
    "    if not os.path.exists(image_directory) or not os.path.isdir(image_directory):\n",
    "        print(f\"Error: The specified directory '{image_directory}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    os.environ['PADDLEOCR_MODELS'] = '/Users/user/Downloads/PaddleOCR'\n",
    "    os.environ['PADDLEOCR_REC_MODEL_DIR'] = 'PaddleOCR/inference/en_PP-OCRv4_rec'\n",
    "    os.environ['PADDLEOCR_DET_MODEL_DIR'] = 'PaddleOCR/output/det_db_inference'\n",
    "    # Initialize TesseractOCR with user-defined parameters\n",
    "    paddle_ocr = PaddleOCR(lang=\"en\")\n",
    "    \n",
    "    #   paddle_ocr = PaddleOCR(lang=\"en\", kw={\"use_dilation\": True})\n",
    "    # Process each image in the directory\n",
    "    for filename in os.listdir(image_directory):\n",
    "        try:\n",
    "            # Construct the image file path\n",
    "            img_path = os.path.join(image_directory, filename)\n",
    "\n",
    "            # Check if the file is an image (you can improve this check if needed)\n",
    "            if not img_path.lower().endswith(('.jpg')):\n",
    "                continue\n",
    "\n",
    "            # Define the image\n",
    "            img = Image(src=img_path)\n",
    "\n",
    "            # Extract tables using img2table\n",
    "            extracted_tables = img.extract_tables(\n",
    "                ocr=paddle_ocr,\n",
    "                implicit_rows=False,\n",
    "                borderless_tables=True,\n",
    "                min_confidence=50\n",
    "            )\n",
    "            # Load the image for visualization\n",
    "            table_img = cv2.imread(img_path)\n",
    "\n",
    "            # Draw rectangles around the extracted table cells\n",
    "            for table in extracted_tables:\n",
    "                for row in table.content.values():\n",
    "                    for cell in row:\n",
    "                        cv2.rectangle(table_img, (cell.bbox.x1, cell.bbox.y1), (cell.bbox.x2, cell.bbox.y2), (255, 0, 0), 2)\n",
    "            # Save the image with rectangles\n",
    "            output_image_path = os.path.join(cells_dir, f\"table_image_{os.path.splitext(filename)[0]}.jpg\")\n",
    "            cv2.imwrite(output_image_path, table_img)\n",
    "            print(f\"Image with rectangles saved to {output_image_path}\")\n",
    "\n",
    "            # Display the image with rectangles\n",
    "            # PILImage.fromarray(table_img).show()\n",
    "\n",
    "            # Convert the extracted table to an Excel file\n",
    "            output_filename = f\"table_{os.path.splitext(filename)[0]}.xlsx\"\n",
    "            output_path = os.path.join(xlsx_dir, output_filename)\n",
    "\n",
    "            img.to_xlsx(output_path, implicit_rows=True, borderless_tables=True, ocr=paddle_ocr)\n",
    "\n",
    "            print(f\"Table data for {filename} saved to {output_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "layout_model = PaddleDetectionLayoutModel(\n",
    "    config_path=\"lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config\",\n",
    "    label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"},\n",
    "    enforce_cpu=True,\n",
    ")\n",
    "\n",
    "#MAIN\n",
    "user_folder_path = os.path.join(os.getcwd(), 'user')\n",
    "detect_tables (user_folder_path, layout_model)  \n",
    "process_images(cropped_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "maeDsa48IPGc",
    "outputId": "5029a24b-71db-4e46-897d-7629d207817a"
   },
   "outputs": [],
   "source": [
    "#LAYOUT BASE\n",
    "\n",
    "# import os\n",
    "# import cv2\n",
    "# import layoutparser as lp\n",
    "\n",
    "# # Directory\n",
    "# if not os.path.exists('cropped'):\n",
    "#     os.makedirs('cropped')\n",
    "\n",
    "# # Get list of all images in the 'user' directory\n",
    "# image_files = [f for f in os.listdir('user') if f.endswith('.jpg')]\n",
    "\n",
    "# for image_file in image_files:\n",
    "#     try:\n",
    "#         # Load image\n",
    "#         image_path = os.path.join('user', image_file)\n",
    "#         image = cv2.imread(image_path)\n",
    "#         image = image[..., ::-1]\n",
    "\n",
    "#         # Load model\n",
    "#         model = lp.PaddleDetectionLayoutModel(\n",
    "#             config_path=\"lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config\",\n",
    "#             threshold=0.2,\n",
    "#             label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"},\n",
    "#             enforce_cpu=True,\n",
    "#             enable_mkldnn=True\n",
    "#         )\n",
    "\n",
    "#         # Detect layout\n",
    "#         layout = model.detect(image)\n",
    "\n",
    "#         # Initialize a counter for the cropped tables\n",
    "#         counter = 1\n",
    "\n",
    "#         for l in layout:\n",
    "#             if l.type == 'Table':\n",
    "#                 x1 = int(l.block.x_1)\n",
    "#                 y1 = int(l.block.y_1)\n",
    "#                 x2 = int(l.block.x_2)\n",
    "#                 y2 = int(l.block.y_2)\n",
    "#                 im = cv2.imread(image_path)\n",
    "#                 cropped_folder = 'cropped'\n",
    "#                 cropped_filename = os.path.join(cropped_folder, f'cropped_{os.path.splitext(image_file)[0]}_{counter}.jpg')\n",
    "#                 cropped_image = im[y1:y2, x1:x2]\n",
    "#                 cv2.imwrite(cropped_filename, cropped_image)\n",
    "\n",
    "#                 counter += 1\n",
    "\n",
    "#         print(f\"{image_file}: {counter - 1} tables have been extracted and saved.\")\n",
    "\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"{image_file} not found. Please make sure the image file exists.\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred for {image_file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFmliG8Ea7u5"
   },
   "source": [
    "# **Text Detection and Recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PaddleOCRbase\n",
    "\n",
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from paddleocr import PaddleOCR\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Initialize PaddleOCR\n",
    "# ocr = PaddleOCR(\n",
    "#     rec_model_dir='PaddleOCR/inference/en_PP-OCRv3_rec',\n",
    "#     det_model_dir='PaddleOCR/output/det_db_inference',\n",
    "#     use_gpu=False,\n",
    "#     show_log=False\n",
    "# )\n",
    "\n",
    "# # Initialize model for layout detection\n",
    "# layout_model = lp.PaddleDetectionLayoutModel(\n",
    "#     config_path=\"lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config\",\n",
    "#     threshold=0.2,\n",
    "#     label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"},\n",
    "#     enforce_cpu=True,\n",
    "#     enable_mkldnn=True\n",
    "# )\n",
    "\n",
    "# # Directory paths\n",
    "# user_directory = 'user'\n",
    "# cropped_directory = 'cropped'\n",
    "# detection_directory = 'detection'\n",
    "# boxes_directory = 'boxes'\n",
    "# nms_directory = 'nms'\n",
    "# nms_data_directory = 'nms_data'\n",
    "# xlsx_directory = 'xlsx'\n",
    "\n",
    "# # Create output directories if they don't exist\n",
    "# for directory in [cropped_directory, detection_directory, boxes_directory, nms_directory, nms_data_directory, xlsx_directory]:\n",
    "#     os.makedirs(directory, exist_ok=True)\n",
    "# horiz_boxes = []\n",
    "# vert_boxes = []\n",
    "# # List all image files in the 'user' directory\n",
    "# image_files = [f for f in os.listdir(user_directory) if f.endswith('.jpg')]\n",
    "\n",
    "# for image_file in image_files:\n",
    "#     try:\n",
    "#         # Load image\n",
    "#         image_path = os.path.join(user_directory, image_file)\n",
    "#         image = cv2.imread(image_path)\n",
    "#         image = image[..., ::-1]  # Convert BGR to RGB\n",
    "\n",
    "#         # Detect layout\n",
    "#         layout = layout_model.detect(image)\n",
    "\n",
    "#         # Initialize a counter for the cropped tables\n",
    "#         counter = 1\n",
    "#         table_boxes = []\n",
    "#         for l in layout:\n",
    "#             if l.type == 'Table':\n",
    "#                 x1 = int(l.block.x_1)\n",
    "#                 y1 = int(l.block.y_1)\n",
    "#                 x2 = int(l.block.x_2)\n",
    "#                 y2 = int(l.block.y_2)\n",
    "\n",
    "#                 # Crop the table from the image\n",
    "#                 cropped_image = image[y1:y2, x1:x2]\n",
    "\n",
    "#                 # Save the cropped table\n",
    "#                 cropped_filename = os.path.join(cropped_directory, f'cropped_{os.path.splitext(image_file)[0]}_{counter}.jpg')\n",
    "#                 cv2.imwrite(cropped_filename, cropped_image)\n",
    "\n",
    "#                 counter += 1\n",
    "#                 table_boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "#         print(f\"{image_file}: {counter - 1} tables have been extracted and saved.\")\n",
    "\n",
    "#         # ocr = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=False)\n",
    "\n",
    "#         # Directory\n",
    "#         base_directory = 'cropped'\n",
    "#         os.makedirs('detection', exist_ok=True)\n",
    "#         os.makedirs('boxes', exist_ok=True)\n",
    "#         os.makedirs('nms', exist_ok=True)\n",
    "#         os.makedirs('nms_data', exist_ok=True)\n",
    "#         os.makedirs('xlsx', exist_ok=True)\n",
    "\n",
    "#         def extract_data(result):\n",
    "#             boxes = [line[0][0] for line in result]\n",
    "#             texts = [line[1][0] for line in result]\n",
    "#             probabilities = [line[1][1] for line in result]\n",
    "#             return boxes, texts, probabilities\n",
    "\n",
    "#         # List of image filenames\n",
    "#         image_filenames = [f for f in os.listdir(base_directory) if f.endswith('.jpg')]\n",
    "\n",
    "#         if not image_filenames:\n",
    "#             print(\"No cropped tables found in the 'cropped' directory.\")\n",
    "#         else:\n",
    "#             for filename in image_filenames:\n",
    "#                 # Determine the page number and identifier\n",
    "#                 identifier = filename.split('_')[-1].split('.')[0]\n",
    "#                 page_number = filename.split('_')[-2]\n",
    "\n",
    "#                 # Read the image\n",
    "#                 image = cv2.imread(os.path.join(base_directory, filename))\n",
    "\n",
    "#                 # Perform OCR on the image\n",
    "#                 result = ocr.ocr(image)\n",
    "\n",
    "#                 # Extract data from the OCR result for this page\n",
    "#                 boxes, texts, probabilities = extract_data(result)\n",
    "\n",
    "#                 # Extract bounding boxes and image dimensions\n",
    "#                 image_height, image_width = image.shape[:2]\n",
    "\n",
    "#                 # Define the text and image file names\n",
    "#                 text_file_name = f'boxes_{page_number}_{identifier}.txt'\n",
    "#                 image_file_name = f'detection_{filename}'\n",
    "\n",
    "#                 # Use extracted coordinates\n",
    "#                 image_boxes = image.copy()\n",
    "\n",
    "#                 # Add the detected text\n",
    "#                 for box, text in zip(boxes, texts):\n",
    "#                     x1, y1 = int(box[0][0]), int(box[0][1])\n",
    "#                     x2, y2 = int(box[2][0]), int(box[2][1])\n",
    "#                     cv2.rectangle(image_boxes, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
    "\n",
    "#                     # Draw text\n",
    "#                     cv2.putText(image_boxes, str(text), (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "#                     width_h, width_v = image_width, int(box[2][0] - box[0][0])\n",
    "#                     height_h, height_v = int(box[2][1] - box[0][1]), image_height\n",
    "\n",
    "#                     horiz_boxes.append([x_h, y_h, x_h + width_h, y_h + height_h])\n",
    "#                     vert_boxes.append([x_v, y_v, x_v + width_v, y_v + height_v])\n",
    "\n",
    "#                     cv2.rectangle(image_boxes, (x_h, y_h), (x_h + width_h, y_h + height_h), (0, 0, 255), 1)\n",
    "#                     cv2.rectangle(image_boxes, (x_v, y_v), (x_v + width_v, y_v + height_v), (0, 255, 0), 1)\n",
    "\n",
    "\n",
    "#                     horiz_boxes.append([x_h, y_h, x_h + width_h, y_h + height_h])\n",
    "#                     vert_boxes.append([x_v, y_v, x_v + width_v, y_v + height_v])\n",
    "\n",
    "#                     cv2.rectangle(image_boxes, (x_h, y_h), (x_h + width_h, y_h + height_h), (0, 0, 255), 1)\n",
    "#                     cv2.rectangle(image_boxes, (x_v, y_v), (x_v + width_v, y_v + height_v), (0, 255, 0), 1)\n",
    "\n",
    "#                 def calculate_intersection(box1, box2):\n",
    "#                     x1 = max(box1[0], box2[0])\n",
    "#                     y1 = max(box1[1], box2[1])\n",
    "#                     x2 = min(box1[0] + box1[2], box2[0] + box2[2])\n",
    "#                     y2 = min(box1[1] + box1[3], box2[1] + box2[3])\n",
    "#                     width = max(0, x2 - x1)\n",
    "#                     height = max(0, y2 - y1)\n",
    "#                     return width * height\n",
    "\n",
    "#                 def calculate_union(box1, box2):\n",
    "#                     area1 = box1[2] * box1[3]\n",
    "#                     area2 = box2[2] * box2[3]\n",
    "#                     union = area1 + area2 - calculate_intersection(box1, box2)\n",
    "#                     return union\n",
    "\n",
    "#                 # Add the detected text\n",
    "#                 for box, text in zip(boxes, texts):\n",
    "#                     # Extract the coordinates\n",
    "#                     x, y = int(box[0]), int(box[1])\n",
    "\n",
    "#                     # Ensure the text is a string\n",
    "#                     text_str = ' '.join(text) if isinstance(text, list) else text\n",
    "\n",
    "#                     # Add the text\n",
    "#                     cv2.putText(image_boxes, text_str, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (222, 0, 0), thickness=1, lineType=cv2.LINE_AA)\n",
    "#                     width_h, width_v = image_width, int(box[2][0] - box[0][0])\n",
    "#                     height_h, height_v = int(box[2][1] - box[0][1]), image_height\n",
    "\n",
    "#                     image_height, image_width = image.shape[:2]\n",
    "\n",
    "#                     # Use extracted coordinates\n",
    "#                     image_boxes = image.copy()\n",
    "\n",
    "#                     # Initialize lists to store horizontal and vertical boxes\n",
    "#                     horiz_boxes = []\n",
    "#                     vert_boxes = []\n",
    "\n",
    "#                     # Add the detected text\n",
    "#                     for box, text in zip(boxes, texts):\n",
    "#                         x1, y1 = int(box[0][0]), int(box[0][1])\n",
    "#                         x2, y2 = int(box[2][0]), int(box[2][1])\n",
    "\n",
    "#                         # Draw rectangles for horizontal lines\n",
    "#                         cv2.rectangle(image_boxes, (0, y1), (image_width, y2), (0, 0, 255), 1)\n",
    "#                         horiz_boxes.append([0, y1, image_width, y2])\n",
    "\n",
    "#                         # Draw rectangles for vertical lines\n",
    "#                         cv2.rectangle(image_boxes, (x1, 0), (x2, image_height), (0, 255, 0), 1)\n",
    "#                         vert_boxes.append([x1, 0, x2, image_height])\n",
    "\n",
    "#                     # Save the horz_vert image with horizontal and vertical boxes\n",
    "#                     output_file_path = os.path.join(nms_directory, f'horiz_vert_{filename}')\n",
    "#                     cv2.imwrite(output_file_path, image_boxes)\n",
    "\n",
    "#                     # Apply NMS for horizontal lines\n",
    "#                     horiz_out = tf.image.non_max_suppression(\n",
    "#                         np.array(horiz_boxes), probabilities, max_output_size=1000, iou_threshold=0.1, name=None\n",
    "#                     )\n",
    "\n",
    "#                     # Apply NMS for vertical lines\n",
    "#                     vert_out = tf.image.non_max_suppression(\n",
    "#                         np.array(vert_boxes), probabilities, max_output_size=1000, iou_threshold=0.1, name=None\n",
    "#                     )\n",
    "\n",
    "#                     # Draw horizontal lines\n",
    "#                     for val in horiz_out:\n",
    "#                         box = np.array(horiz_boxes[val])\n",
    "#                         cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (0, 0, 255), 1)\n",
    "\n",
    "#                     # Draw vertical lines\n",
    "#                     for val in vert_out:\n",
    "#                         box = np.array(vert_boxes[val])\n",
    "#                         cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 1)\n",
    "\n",
    "#                     # Display the result or save the image\n",
    "#                     cv2.imshow(\"Result\", image)\n",
    "#                     cv2.waitKey(0)\n",
    "#                     cv2.destroyAllWindows()\n",
    "#                 out_array = [[\"\" for i in range(len(vert_lines))] for j in range(len(horiz_lines))]\n",
    "#                 unordered_boxes = []\n",
    "\n",
    "#                 for i in vert_lines:\n",
    "#                     print(vert_boxes[i])\n",
    "#                     unordered_boxes.append(vert_boxes[i][0])\n",
    "\n",
    "#                 ordered_boxes = np.argsort(unordered_boxes)\n",
    "\n",
    "#                 def intersection(box_1, box_2):\n",
    "#                     return [box_2[0], box_1[1], box_2[2], box_1[3]]\n",
    "\n",
    "#                 def iou(box_1, box_2):\n",
    "#                     x_1 = max(box_1[0], box_2[0])\n",
    "#                     y_1 = max(box_1[1], box_2[1])\n",
    "#                     x_2 = min(box_1[2], box_2[2])\n",
    "#                     y_2 = min(box_1[3], box_2[3])\n",
    "\n",
    "#                     inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))\n",
    "#                     if inter == 0:\n",
    "#                         return 0\n",
    "\n",
    "#                     box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))\n",
    "#                     box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))\n",
    "\n",
    "#                     return inter / float(box_1_area + box_2_area - inter)\n",
    "\n",
    "#                 for i in range(len(horiz_lines)):\n",
    "#                     for j in range(len(vert_lines)):\n",
    "#                         resultant = intersection(horiz_boxes[horiz_lines[i]], vert_boxes[vert_lines[ordered_boxes[j]]])\n",
    "\n",
    "#                         for b in range(len(boxes)):\n",
    "#                             the_box = [boxes[b][0][0], boxes[b][0][1], boxes[b][2][0], boxes[b][2][1]]\n",
    "#                             if iou(resultant, the_box) > 0.1:\n",
    "#                                 out_array[i][j] = texts[b]\n",
    "\n",
    "#                 out_array = np.array(out_array)\n",
    "\n",
    "#                 # Save the CSV\n",
    "#                 xlsx_file_name = f'output_{filename}.xlsx'\n",
    "#                 pd.DataFrame(out_array).to_excel(os.path.join('xlsx', xlsx_file_name), index=False, encoding='utf-8')\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {image_file}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_page1.jpg: 1 tables have been extracted and saved.\n",
      "Modified image saved as 'detection_processed_page1.jpg'\n"
     ]
    }
   ],
   "source": [
    "# #FUNCTIONS (PaddleOCRbase with function B)\n",
    "# from typing import Tuple\n",
    "# from layoutparser import PaddleDetectionLayoutModel\n",
    "# from pytesseract import pytesseract\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Function to perform OCR using PyTesseract\n",
    "# def perform_ocr(image: np.ndarray) -> Tuple[list, list, list]:\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "#     custom_config = r'--oem 3 --psm 6'\n",
    "#     result = pytesseract.image_to_data(binary, output_type=pytesseract.Output.DICT, config=custom_config)\n",
    "\n",
    "#     boxes = []\n",
    "#     texts = []\n",
    "#     probabilities = []\n",
    "\n",
    "#     for i in range(len(result['text'])):\n",
    "#         if int(result['conf'][i]) > 0:\n",
    "#             x = int(result['left'][i])\n",
    "#             y = int(result['top'][i])\n",
    "#             w = int(result['width'][i])\n",
    "#             h = int(result['height'][i])\n",
    "#             box = [x, y, x + w, y + h]\n",
    "#             text = result['text'][i]\n",
    "#             confidence = int(result['conf'][i])\n",
    "\n",
    "#             boxes.append(box)\n",
    "#             texts.append(text)\n",
    "#             probabilities.append(confidence)\n",
    "\n",
    "#     return boxes, texts, probabilities\n",
    "\n",
    "# def process_image(file_path, layout_model):\n",
    "#     try:\n",
    "#         # Load image\n",
    "#         image = cv2.imread(file_path)\n",
    "#         image = image[..., ::-1]  # Convert BGR to RGB\n",
    "\n",
    "#         # Detect layout\n",
    "#         layout = layout_model.detect(image)\n",
    "\n",
    "#         # Initialize a counter for the cropped tables\n",
    "#         counter = 1\n",
    "#         table_boxes = []\n",
    "#         for l in layout:\n",
    "#             if l.type == 'Table':\n",
    "#                 x1 = int(l.block.x_1)\n",
    "#                 y1 = int(l.block.y_1)\n",
    "#                 x2 = int(l.block.x_2)\n",
    "#                 y2 = int(l.block.y_2)\n",
    "\n",
    "#                 # Crop the table from the image\n",
    "#                 cropped_image = image[y1:y2, x1:x2]\n",
    "\n",
    "#                 # Save the cropped table\n",
    "#                 cropped_filename = os.path.join('cropped', f'cropped_{os.path.splitext(os.path.basename(file_path))[0]}_{counter}.jpg')\n",
    "#                 cv2.imwrite(cropped_filename, cropped_image)\n",
    "\n",
    "#                 counter += 1\n",
    "#                 table_boxes.append([x1, y1, x2, y2])\n",
    "#         boxes = table_boxes\n",
    "#         print(f\"{os.path.basename(file_path)}: {counter - 1} tables have been extracted and saved.\")\n",
    "\n",
    "#         # Directory\n",
    "#         os.makedirs('detection', exist_ok=True)\n",
    "#         os.makedirs('boxes', exist_ok=True)\n",
    "#         os.makedirs('nms', exist_ok=True)\n",
    "#         os.makedirs('nms_data', exist_ok=True)\n",
    "#         os.makedirs('xlsx', exist_ok=True)\n",
    "\n",
    "#         # Perform OCR on the image\n",
    "#         result = perform_ocr(image)\n",
    "\n",
    "#         # Extract data from the OCR result for this page\n",
    "#         boxes, texts, probabilities = result\n",
    "\n",
    "#         # Extract bounding boxes and image dimensions\n",
    "#         image_height, image_width = image.shape[:2]\n",
    "\n",
    "#         # Create an image_boxes variable for drawing rectangles and text\n",
    "#         image_boxes = image.copy()\n",
    "\n",
    "#         # Define the text and image file names\n",
    "#         filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "#         text_file_name = f'boxes_{filename}.txt'\n",
    "#         for box, text in zip(boxes, texts):\n",
    "#             x1, y1, x2, y2 = box\n",
    "#             x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "#             # Draw rectangle\n",
    "#             cv2.rectangle(image_boxes, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
    "\n",
    "#             # Draw text\n",
    "#             cv2.putText(image_boxes, text, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "#         # Save the modified image\n",
    "#         detection_folder = 'detection'\n",
    "#         detection_filename = f'detection_{filename}.jpg'\n",
    "#         cv2.imwrite(os.path.join(detection_folder, detection_filename), image_boxes)\n",
    "\n",
    "#         print(f\"Modified image saved as '{detection_filename}'\")\n",
    "\n",
    "#         # Use extracted coordinates\n",
    "#         image_boxes = image.copy()\n",
    "\n",
    "#         horiz_boxes = []\n",
    "#         vert_boxes = []\n",
    "\n",
    "#         for box in boxes:\n",
    "#             x_h, x_v = 0, int(box[0])\n",
    "#             y_h, y_v = int(box[1]), 0\n",
    "#             width_h, width_v = image_width, int(box[2] - box[0])\n",
    "#             height_h, height_v = int(box[3] - box[1]), image_height\n",
    "\n",
    "#             horiz_boxes.append([x_h, y_h, x_h + width_h, y_h + height_h])\n",
    "#             vert_boxes.append([x_v, y_v, x_v + width_v, y_v + height_v])\n",
    "\n",
    "#             cv2.rectangle(image_boxes, (x_h, y_h), (x_h + width_h, y_h + height_h), (0, 0, 255), 1)\n",
    "#             cv2.rectangle(image_boxes, (x_v, y_v), (x_v + width_v, y_v + height_v), (0, 255, 0), 1)\n",
    "\n",
    "#         # Save the horz_vert image with horizontal and vertical boxes\n",
    "#         output_file_path = os.path.join('nms', f'horiz_vert_{filename}.jpg')\n",
    "#         cv2.imwrite(output_file_path, image_boxes)\n",
    "\n",
    "#         # Apply NMS and get horizontal and vertical lines\n",
    "#         im = image.copy()\n",
    "\n",
    "#         horiz_out = tf.image.non_max_suppression(\n",
    "#             horiz_boxes, probabilities, max_output_size=1000, iou_threshold=0.1, name=None\n",
    "#         )\n",
    "\n",
    "#         vert_out = tf.image.non_max_suppression(\n",
    "#             vert_boxes, probabilities, max_output_size=1000, iou_threshold=0.1, name=None\n",
    "#         )\n",
    "\n",
    "#         horiz_lines = np.sort(np.array(horiz_out))\n",
    "#         vert_lines = np.sort(np.array(vert_out))\n",
    "\n",
    "#         im_nms = image.copy()\n",
    "\n",
    "#         # Draw horizontal lines\n",
    "#         if len(horiz_lines) > 0:\n",
    "#             for val in horiz_lines:\n",
    "#                 cv2.rectangle(im_nms, (int(horiz_boxes[val][0]), int(horiz_boxes[val][1])),\n",
    "#                               (int(horiz_boxes[val][2]), int(horiz_boxes[val][3])), (0, 0, 255), 1)\n",
    "\n",
    "#         # Draw vertical lines\n",
    "#         if len(vert_lines) > 0:\n",
    "#             for val in vert_lines:\n",
    "#                 cv2.rectangle(im_nms, (int(vert_boxes[val][0]), int(vert_boxes[val][1])),\n",
    "#                               (int(vert_boxes[val][2]), int(vert_boxes[val][3])), (255, 0, 0), 1)\n",
    "\n",
    "#         out_array = [[\"\" for i in range(len(vert_lines))] for j in range(len(horiz_lines))]\n",
    "#         unordered_boxes = []\n",
    "\n",
    "#         for i in vert_lines:\n",
    "#             unordered_boxes.append(vert_boxes[i][0])\n",
    "\n",
    "#         ordered_boxes = np.argsort(unordered_boxes)\n",
    "\n",
    "#         def intersection(box_1, box_2):\n",
    "#             return [box_2[0], box_1[1], box_2[2], box_1[3]]\n",
    "\n",
    "#         def iou(box_1, box_2):\n",
    "#             x_1 = max(box_1[0], box_2[0])\n",
    "#             y_1 = max(box_1[1], box_2[1])\n",
    "#             x_2 = min(box_1[2], box_2[2])\n",
    "#             y_2 = min(box_1[3], box_2[3])\n",
    "\n",
    "#             inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))\n",
    "#             if inter == 0:\n",
    "#                 return 0\n",
    "\n",
    "#             box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))\n",
    "#             box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))\n",
    "\n",
    "#             return inter / float(box_1_area + box_2_area - inter)\n",
    "\n",
    "#         for i in range(len(horiz_lines)):\n",
    "#             for j in range(len(vert_lines)):\n",
    "#                 resultant = intersection(horiz_boxes[horiz_lines[i]], vert_boxes[vert_lines[ordered_boxes[j]]])\n",
    "\n",
    "#                 for b in range(len(boxes)):\n",
    "#                     the_box = [boxes[b][0], boxes[b][1], boxes[b][2], boxes[b][3]]\n",
    "#                     if iou(resultant, the_box) > 0.1:\n",
    "#                         out_array[i][j] = texts[b]\n",
    "\n",
    "#         out_array = np.array(out_array)\n",
    "\n",
    "#         # Save the CSV\n",
    "#         xlsx_file_name = f'output_{filename}.xlsx'\n",
    "#         pd.DataFrame(out_array).to_excel(os.path.join('xlsx', xlsx_file_name), index=False)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {os.path.basename(file_path)}: {e}\")\n",
    "\n",
    "# # Directory paths\n",
    "# user_directory = 'user'\n",
    "\n",
    "# # Initialize model for layout detection\n",
    "# layout_model = PaddleDetectionLayoutModel(\n",
    "#     config_path=\"lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config\",\n",
    "#     threshold=0.2,\n",
    "#     label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"},\n",
    "#     enforce_cpu=True,\n",
    "#     enable_mkldnn=True\n",
    "# )\n",
    "\n",
    "# # List all image files in the 'user' directory\n",
    "# image_files = [f for f in os.listdir(user_directory) if f.endswith('.jpg')]\n",
    "\n",
    "# for image_file in image_files:\n",
    "#     image_path = os.path.join(user_directory, image_file)\n",
    "#     process_image(image_path, layout_model)\n",
    "    \n",
    "    \n",
    "#     #THISHISHSISHISHISHISISHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl#sha256=83276fc78a70045627144786b52e1f2728ad5e29e5e43916ec37ea9c26a11212 (from -r requirements.txt (line 72))\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "Collecting absl-py==1.4.0 (from -r requirements.txt (line 1))\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting aiohttp==3.8.6 (from -r requirements.txt (line 2))\n",
      "  Using cached aiohttp-3.8.6-cp37-cp37m-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiosignal==1.3.1 (from -r requirements.txt (line 3))\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting alabaster==0.7.13 (from -r requirements.txt (line 4))\n",
      "  Using cached alabaster-0.7.13-py3-none-any.whl (13 kB)\n",
      "Collecting albumentations==1.3.1 (from -r requirements.txt (line 5))\n",
      "  Using cached albumentations-1.3.1-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting altair==4.2.2 (from -r requirements.txt (line 6))\n",
      "  Using cached altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "Requirement already satisfied: anyio==3.7.1 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 7)) (3.7.1)\n",
      "Collecting appdirs==1.4.4 (from -r requirements.txt (line 8))\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting argon2-cffi==23.1.0 (from -r requirements.txt (line 9))\n",
      "  Using cached argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting argon2-cffi-bindings==21.2.0 (from -r requirements.txt (line 10))\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-win_amd64.whl (30 kB)\n",
      "Requirement already satisfied: astor==0.8.1 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 11)) (0.8.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 12)) (1.6.3)\n",
      "Collecting async-timeout==4.0.3 (from -r requirements.txt (line 13))\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: attrdict==2.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 14)) (2.0.1)\n",
      "Collecting attrs==23.1.0 (from -r requirements.txt (line 15))\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting audioread==3.0.1 (from -r requirements.txt (line 16))\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting autograd==1.6.2 (from -r requirements.txt (line 17))\n",
      "  Using cached autograd-1.6.2-py3-none-any.whl.metadata (706 bytes)\n",
      "Requirement already satisfied: Babel==2.13.1 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 18)) (2.13.1)\n",
      "Requirement already satisfied: backcall==0.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 19)) (0.2.0)\n",
      "Collecting bce-python-sdk==0.8.97 (from -r requirements.txt (line 20))\n",
      "  Using cached bce_python_sdk-0.8.97-py3-none-any.whl.metadata (319 bytes)\n",
      "Collecting beautifulsoup4==4.11.2 (from -r requirements.txt (line 21))\n",
      "  Using cached beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
      "Collecting bidict==0.22.1 (from -r requirements.txt (line 22))\n",
      "  Using cached bidict-0.22.1-py3-none-any.whl (35 kB)\n",
      "Collecting blinker==1.4 (from -r requirements.txt (line 23))\n",
      "  Using cached blinker-1.4.tar.gz (111 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting blis==0.7.11 (from -r requirements.txt (line 24))\n",
      "  Using cached blis-0.7.11-cp37-cp37m-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting bqplot==0.12.42 (from -r requirements.txt (line 25))\n",
      "  Using cached bqplot-0.12.42-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting branca==0.7.0 (from -r requirements.txt (line 26))\n",
      "  Using cached branca-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting build==1.0.3 (from -r requirements.txt (line 27))\n",
      "  Using cached build-1.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting CacheControl==0.13.1 (from -r requirements.txt (line 28))\n",
      "  Using cached cachecontrol-0.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: cachetools==5.3.2 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 29)) (5.3.2)\n",
      "Collecting catalogue==2.0.10 (from -r requirements.txt (line 30))\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: certifi==2023.7.22 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 31)) (2023.7.22)\n",
      "Collecting chardet==5.2.0 (from -r requirements.txt (line 32))\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 33)) (3.3.2)\n",
      "Requirement already satisfied: click==8.1.7 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 34)) (8.1.7)\n",
      "Collecting click-plugins==1.1.1 (from -r requirements.txt (line 35))\n",
      "  Using cached click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting cligj==0.7.2 (from -r requirements.txt (line 36))\n",
      "  Using cached cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Collecting cloudpickle==2.2.1 (from -r requirements.txt (line 37))\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting cmake==3.27.7 (from -r requirements.txt (line 38))\n",
      "  Using cached cmake-3.27.7-py2.py3-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting colorcet==3.0.1 (from -r requirements.txt (line 39))\n",
      "  Using cached colorcet-3.0.1-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting colorlover==0.3.0 (from -r requirements.txt (line 40))\n",
      "  Using cached colorlover-0.3.0-py3-none-any.whl (8.9 kB)\n",
      "Collecting colour==0.1.5 (from -r requirements.txt (line 41))\n",
      "  Using cached colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
      "Collecting community==1.0.0b1 (from -r requirements.txt (line 42))\n",
      "  Using cached community-1.0.0b1.tar.gz (2.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting confection==0.1.3 (from -r requirements.txt (line 43))\n",
      "  Using cached confection-0.1.3-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting cons==0.4.6 (from -r requirements.txt (line 44))\n",
      "  Using cached cons-0.4.6.tar.gz (26 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting contextlib2==21.6.0 (from -r requirements.txt (line 45))\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting cryptography==41.0.5 (from -r requirements.txt (line 46))\n",
      "  Using cached cryptography-41.0.5-cp37-abi3-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: cssselect==1.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 47)) (1.2.0)\n",
      "Collecting cufflinks==0.17.3 (from -r requirements.txt (line 48))\n",
      "  Using cached cufflinks-0.17.3.tar.gz (81 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cupy-cuda11x==11.0.0 (from -r requirements.txt (line 49))\n",
      "  Using cached cupy_cuda11x-11.0.0-cp37-cp37m-win_amd64.whl (62.2 MB)\n",
      "Collecting cvxopt==1.3.2 (from -r requirements.txt (line 50))\n",
      "  Using cached cvxopt-1.3.2.tar.gz (4.1 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting cvxpy==1.3.2 (from -r requirements.txt (line 51))\n",
      "  Using cached cvxpy-1.3.2-cp37-cp37m-win_amd64.whl.metadata (8.9 kB)\n",
      "Collecting cymem==2.0.8 (from -r requirements.txt (line 52))\n",
      "  Using cached cymem-2.0.8-cp37-cp37m-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: Cython==3.0.5 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 53)) (3.0.5)\n",
      "Collecting datascience==0.17.6 (from -r requirements.txt (line 54))\n",
      "  Using cached datascience-0.17.6-py3-none-any.whl (732 kB)\n",
      "Collecting db-dtypes==1.1.1 (from -r requirements.txt (line 55))\n",
      "  Using cached db_dtypes-1.1.1-py2.py3-none-any.whl (14 kB)\n",
      "Collecting dbus-python==1.2.18 (from -r requirements.txt (line 56))\n",
      "  Using cached dbus-python-1.2.18.tar.gz (578 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting debugpy==1.6.6 (from -r requirements.txt (line 57))\n",
      "  Using cached debugpy-1.6.6-cp37-cp37m-win_amd64.whl (4.8 MB)\n",
      "Collecting decorator==4.4.2 (from -r requirements.txt (line 58))\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting defusedxml==0.7.1 (from -r requirements.txt (line 59))\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting diskcache==5.6.3 (from -r requirements.txt (line 60))\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting distro==1.7.0 (from -r requirements.txt (line 61))\n",
      "  Using cached distro-1.7.0-py3-none-any.whl (20 kB)\n",
      "Collecting dlib==19.24.2 (from -r requirements.txt (line 62))\n",
      "  Using cached dlib-19.24.2.tar.gz (11.8 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting dm-tree==0.1.8 (from -r requirements.txt (line 63))\n",
      "  Using cached dm_tree-0.1.8-cp37-cp37m-win_amd64.whl (102 kB)\n",
      "Collecting docutils==0.18.1 (from -r requirements.txt (line 64))\n",
      "  Using cached docutils-0.18.1-py2.py3-none-any.whl (570 kB)\n",
      "Collecting dopamine-rl==4.0.6 (from -r requirements.txt (line 65))\n",
      "  Using cached dopamine_rl-4.0.6-py3-none-any.whl (179 kB)\n",
      "Collecting duckdb==0.9.2 (from -r requirements.txt (line 66))\n",
      "  Using cached duckdb-0.9.2-cp37-cp37m-win_amd64.whl.metadata (798 bytes)\n",
      "Collecting earthengine-api==0.1.379 (from -r requirements.txt (line 67))\n",
      "  Using cached earthengine-api-0.1.379.tar.gz (257 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting easydict==1.11 (from -r requirements.txt (line 68))\n",
      "  Using cached easydict-1.11.tar.gz (6.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting ecos==2.0.12 (from -r requirements.txt (line 69))\n",
      "  Using cached ecos-2.0.12-cp37-cp37m-win_amd64.whl (71 kB)\n",
      "Collecting editdistance==0.6.2 (from -r requirements.txt (line 70))\n",
      "  Using cached editdistance-0.6.2-cp37-cp37m-win_amd64.whl (22 kB)\n",
      "Collecting eerepr==0.0.4 (from -r requirements.txt (line 71))\n",
      "  Using cached eerepr-0.0.4-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: entrypoints==0.4 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 73)) (0.4)\n",
      "Requirement already satisfied: et-xmlfile==1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 74)) (1.1.0)\n",
      "Requirement already satisfied: exceptiongroup==1.1.3 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 75)) (1.1.3)\n",
      "Collecting fastcore==1.5.29 (from -r requirements.txt (line 76))\n",
      "  Using cached fastcore-1.5.29-py3-none-any.whl (67 kB)\n",
      "Collecting fastdownload==0.0.7 (from -r requirements.txt (line 77))\n",
      "  Using cached fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Collecting fastjsonschema==2.19.0 (from -r requirements.txt (line 78))\n",
      "  Using cached fastjsonschema-2.19.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting fastprogress==1.0.3 (from -r requirements.txt (line 79))\n",
      "  Using cached fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Collecting fastrlock==0.8.2 (from -r requirements.txt (line 80))\n",
      "  Using cached fastrlock-0.8.2-cp37-cp37m-win_amd64.whl.metadata (9.6 kB)\n",
      "Collecting fiona==1.9.5 (from -r requirements.txt (line 81))\n",
      "  Using cached fiona-1.9.5-cp37-cp37m-win_amd64.whl.metadata (51 kB)\n",
      "Collecting firebase-admin==5.3.0 (from -r requirements.txt (line 82))\n",
      "  Using cached firebase_admin-5.3.0-py3-none-any.whl (117 kB)\n",
      "Requirement already satisfied: flatbuffers==23.5.26 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 83)) (23.5.26)\n",
      "Collecting folium==0.14.0 (from -r requirements.txt (line 84))\n",
      "  Using cached folium-0.14.0-py2.py3-none-any.whl (102 kB)\n",
      "Collecting frozendict==2.3.8 (from -r requirements.txt (line 85))\n",
      "  Using cached frozendict-2.3.8-cp37-cp37m-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: future==0.18.3 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 86)) (0.18.3)\n",
      "Collecting gast==0.5.4 (from -r requirements.txt (line 87))\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting GDAL==3.4.3 (from -r requirements.txt (line 88))\n",
      "  Using cached GDAL-3.4.3.tar.gz (757 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gdown==4.6.6 (from -r requirements.txt (line 89))\n",
      "  Using cached gdown-4.6.6-py3-none-any.whl (14 kB)\n",
      "Collecting geocoder==1.38.1 (from -r requirements.txt (line 90))\n",
      "  Using cached geocoder-1.38.1-py2.py3-none-any.whl (98 kB)\n",
      "Collecting geographiclib==2.0 (from -r requirements.txt (line 91))\n",
      "  Using cached geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "Collecting geopy==2.3.0 (from -r requirements.txt (line 92))\n",
      "  Using cached geopy-2.3.0-py3-none-any.whl (119 kB)\n",
      "Collecting gin-config==0.5.0 (from -r requirements.txt (line 93))\n",
      "  Using cached gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "Collecting glob2==0.7 (from -r requirements.txt (line 94))\n",
      "  Using cached glob2-0.7.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting google==2.0.3 (from -r requirements.txt (line 95))\n",
      "  Using cached google-2.0.3-py2.py3-none-any.whl (45 kB)\n",
      "Collecting google-ai-generativelanguage==0.3.3 (from -r requirements.txt (line 96))\n",
      "  Using cached google_ai_generativelanguage-0.3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting google-api-core==2.11.1 (from -r requirements.txt (line 97))\n",
      "  Using cached google_api_core-2.11.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-python-client==2.84.0 (from -r requirements.txt (line 98))\n",
      "  Using cached google_api_python_client-2.84.0-py2.py3-none-any.whl (11.2 MB)\n",
      "Collecting google-auth==2.17.3 (from -r requirements.txt (line 99))\n",
      "  Using cached google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "Collecting google-auth-httplib2==0.1.1 (from -r requirements.txt (line 100))\n",
      "  Using cached google_auth_httplib2-0.1.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting google-auth-oauthlib==1.0.0 (from -r requirements.txt (line 101))\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-cloud-bigquery==3.12.0 (from -r requirements.txt (line 102))\n",
      "  Using cached google_cloud_bigquery-3.12.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting google-cloud-bigquery-connection==1.12.1 (from -r requirements.txt (line 103))\n",
      "  Using cached google_cloud_bigquery_connection-1.12.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting google-cloud-bigquery-storage==2.22.0 (from -r requirements.txt (line 104))\n",
      "  Using cached google_cloud_bigquery_storage-2.22.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting google-cloud-core==2.3.3 (from -r requirements.txt (line 105))\n",
      "  Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting google-cloud-datastore==2.15.2 (from -r requirements.txt (line 106))\n",
      "  Using cached google_cloud_datastore-2.15.2-py2.py3-none-any.whl (175 kB)\n",
      "Collecting google-cloud-firestore==2.11.1 (from -r requirements.txt (line 107))\n",
      "  Using cached google_cloud_firestore-2.11.1-py2.py3-none-any.whl (283 kB)\n",
      "Collecting google-cloud-functions==1.13.3 (from -r requirements.txt (line 108))\n",
      "  Using cached google_cloud_functions-1.13.3-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting google-cloud-iam==2.12.2 (from -r requirements.txt (line 109))\n",
      "  Using cached google_cloud_iam-2.12.2-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting google-cloud-language==2.9.1 (from -r requirements.txt (line 110))\n",
      "  Using cached google_cloud_language-2.9.1-py2.py3-none-any.whl (99 kB)\n",
      "Collecting google-cloud-resource-manager==1.10.4 (from -r requirements.txt (line 111))\n",
      "  Using cached google_cloud_resource_manager-1.10.4-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting google-cloud-storage==2.8.0 (from -r requirements.txt (line 112))\n",
      "  Using cached google_cloud_storage-2.8.0-py2.py3-none-any.whl (113 kB)\n",
      "Collecting google-cloud-translate==3.11.3 (from -r requirements.txt (line 113))\n",
      "  Using cached google_cloud_translate-3.11.3-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting google-crc32c==1.5.0 (from -r requirements.txt (line 114))\n",
      "  Using cached google_crc32c-1.5.0-cp37-cp37m-win_amd64.whl (27 kB)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 115)) (0.2.0)\n",
      "Collecting google-resumable-media==2.6.0 (from -r requirements.txt (line 116))\n",
      "  Using cached google_resumable_media-2.6.0-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting googleapis-common-protos==1.61.0 (from -r requirements.txt (line 117))\n",
      "  Using cached googleapis_common_protos-1.61.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting googledrivedownloader==0.4 (from -r requirements.txt (line 118))\n",
      "  Using cached googledrivedownloader-0.4-py2.py3-none-any.whl (3.9 kB)\n",
      "Collecting graphviz==0.20.1 (from -r requirements.txt (line 119))\n",
      "  Using cached graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "Collecting greenlet==3.0.1 (from -r requirements.txt (line 120))\n",
      "  Using cached greenlet-3.0.1-cp37-cp37m-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting grpc-google-iam-v1==0.12.7 (from -r requirements.txt (line 121))\n",
      "  Using cached grpc_google_iam_v1-0.12.7-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: grpcio==1.59.2 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 122)) (1.59.2)\n",
      "Collecting grpcio-status==1.48.2 (from -r requirements.txt (line 123))\n",
      "  Using cached grpcio_status-1.48.2-py3-none-any.whl (14 kB)\n",
      "Collecting gspread==3.4.2 (from -r requirements.txt (line 124))\n",
      "  Using cached gspread-3.4.2-py3-none-any.whl (23 kB)\n",
      "Collecting gspread-dataframe==3.3.1 (from -r requirements.txt (line 125))\n",
      "  Using cached gspread_dataframe-3.3.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting gym==0.25.2 (from -r requirements.txt (line 126))\n",
      "  Using cached gym-0.25.2.tar.gz (734 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting gym-notices==0.0.8 (from -r requirements.txt (line 127))\n",
      "  Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Collecting html5lib==1.1 (from -r requirements.txt (line 128))\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Collecting httpimport==1.3.1 (from -r requirements.txt (line 129))\n",
      "  Using cached httpimport-1.3.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting httplib2==0.22.0 (from -r requirements.txt (line 130))\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Collecting hyperopt==0.2.7 (from -r requirements.txt (line 131))\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 9.1 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 0.0.1 Requires-Python >=3.8; 0.0.2 Requires-Python >=3.8; 0.0.3 Requires-Python >=3.8; 1.4.0 Requires-Python >=3.8; 1.4.1 Requires-Python >=3.8; 1.7.0 Requires-Python >=3.8; 1.8.0 Requires-Python >=3.8; 3.0.0 Requires-Python >=3.8; 3.0.0 Requires-Python >=3.8,<3.11; 3.0.1 Requires-Python >=3.8,<3.11; 3.0.2 Requires-Python >=3.8,<3.11; 3.1.0 Requires-Python >=3.8,<3.11; 3.2.0 Requires-Python >=3.8,<3.11; 3.9.0 Requires-Python >=3.8; 3.9.0b0 Requires-Python >=3.8; 3.9.0b1 Requires-Python >=3.8; 3.9.0rc0 Requires-Python >=3.8; 4.0.0 Requires-Python >=3.8,<4.0; 4.1.0 Requires-Python >=3.8,<4.0; 5.0.0 Requires-Python >=3.8,<4.0; 5.1.0 Requires-Python >=3.8; 5.1.0 Requires-Python >=3.8,<4.0; 5.1.1 Requires-Python >=3.8; 5.1.1.dev467 Requires-Python >=3.8,<4.0; 5.1.1.dev516 Requires-Python >=3.8,<4.0; 5.1.1.dev554 Requires-Python >=3.8,<4.0; 5.1.1.dev596 Requires-Python >=3.9,<4.0; 5.1.2 Requires-Python >=3.8; 6.0.0 Requires-Python >=3.9,<4.0; 6.0.1.dev128 Requires-Python >=3.9,<4.0; 6.0.1.dev33 Requires-Python >=3.9,<4.0; 6.0.1.dev58 Requires-Python >=3.9,<4.0; 6.1.0 Requires-Python >=3.9,<4.0; 6.1.1.dev135 Requires-Python >=3.9,<4.0; 6.1.1.dev176 Requires-Python >=3.9,<4.0; 6.1.1.dev22 Requires-Python >=3.9,<4.0; 6.1.1.dev96 Requires-Python >=3.9,<4.0; 6.2.0 Requires-Python >=3.9,<4.0; 7.0.0 Requires-Python >=3.9,<4.0; 7.0.0.dev230 Requires-Python >=3.9,<4.0; 7.0.0.dev439 Requires-Python >=3.9,<4.0; 7.0.0.dev501 Requires-Python >=3.9,<4.0; 7.0.0.dev525 Requires-Python >=3.9,<4.0; 7.0.0.dev627 Requires-Python >=3.9,<4.0; 7.1.0 Requires-Python >=3.9,<4.0; 8.0.0.dev107 Requires-Python >=3.9,<4.0; 8.0.0.dev179 Requires-Python >=3.9,<4.0; 8.0.0.dev21 Requires-Python >=3.9,<4.0; 8.0.0.dev235 Requires-Python >=3.9,<4.0; 8.0.0.dev272 Requires-Python >=3.9,<4.0; 8.0.0.dev321 Requires-Python >=3.9,<4.0; 8.0.0.dev39 Requires-Python >=3.9,<4.0\n",
      "ERROR: Could not find a version that satisfies the requirement ibis-framework==6.2.0 (from versions: 0.3.0, 0.4.0, 0.4.1, 0.5.1, 0.5.2, 0.6.0, 0.6.1, 0.7.0, 0.7.1, 0.8.0, 0.8.1, 0.9.0, 0.10.0, 0.11.1, 0.11.2, 0.12.0, 0.13.0, 0.14.0, 1.0.0, 1.1.0, 1.2.0, 1.3.0, 1.4.0, 2.0.0, 2.1.0, 2.1.1)\n",
      "ERROR: No matching distribution found for ibis-framework==6.2.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install --user -r requirements.txt no need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table data for processed_page1.jpg saved to c:\\Users\\user\\Downloads\\user\\table_processed_page1.xlsx\n",
      "Table data for processed_page1.jpg saved to c:\\Users\\user\\Downloads\\user\\table_processed_page1.xlsx\n"
     ]
    }
   ],
   "source": [
    "#PyteserractBase\n",
    "\n",
    "# from img2table.document import Image\n",
    "# from img2table.ocr import TesseractOCR\n",
    "# import cv2\n",
    "# from PIL import Image as PILImage\n",
    "# import os\n",
    "\n",
    "# def process_image(img_path, user_folder_path, tesseract_ocr):\n",
    "#     try:\n",
    "#         # Define the image\n",
    "#         img = Image(src=img_path)\n",
    "\n",
    "#         # Extract tables\n",
    "#         extracted_tables = img.extract_tables(\n",
    "#             ocr=tesseract_ocr,\n",
    "#             implicit_rows=True,\n",
    "#             borderless_tables=True,\n",
    "#             min_confidence=50\n",
    "#         )\n",
    "\n",
    "#         # Load the image for visualization\n",
    "#         table_img = cv2.imread(img_path)\n",
    "\n",
    "#         # Draw rectangles around the extracted table cells\n",
    "#         for table in extracted_tables:\n",
    "#             for row in table.content.values():\n",
    "#                 for cell in row:\n",
    "#                     cv2.rectangle(table_img, (cell.bbox.x1, cell.bbox.y1), (cell.bbox.x2, cell.bbox.y2), (255, 0, 0), 2)\n",
    "\n",
    "#         # Save the image with rectangles\n",
    "#         output_image_path = os.path.join(user_folder_path, f\"table_image_{os.path.splitext(os.path.basename(img_path))[0]}.png\")\n",
    "#         cv2.imwrite(output_image_path, table_img)\n",
    "#         print(f\"Image with rectangles saved to {output_image_path}\")\n",
    "\n",
    "#         # Display the image with rectangles\n",
    "#         PILImage.fromarray(table_img).show()\n",
    "\n",
    "#         # Convert the extracted table to an Excel file\n",
    "#         output_filename = f\"table_{os.path.splitext(os.path.basename(img_path))[0]}.xlsx\"\n",
    "#         output_path = os.path.join(user_folder_path, output_filename)\n",
    "\n",
    "#         img.to_xlsx(output_path, implicit_rows=True, borderless_tables=True, ocr=tesseract_ocr)\n",
    "\n",
    "#         print(f\"Table data for {os.path.basename(img_path)} saved to {output_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {os.path.basename(img_path)}: {str(e)}\")\n",
    "\n",
    "\n",
    "# # Find the 'user' folder within the current directory\n",
    "# current_directory = os.getcwd()\n",
    "# user_folder_path = os.path.join(current_directory, 'user')\n",
    "\n",
    "# # Check if the 'user' folder exists\n",
    "# if not os.path.exists(user_folder_path) or not os.path.isdir(user_folder_path):\n",
    "#     print(\"Error: The 'user' folder does not exist in the current directory.\")\n",
    "#     exit()\n",
    "\n",
    "# # Initialize TesseractOCR with user-defined parameters\n",
    "# tesseract_ocr = TesseractOCR(n_threads=1, lang=\"eng\")\n",
    "\n",
    "# # Process each image in the 'user' folder\n",
    "# for filename in os.listdir(user_folder_path):\n",
    "#     # Construct the image file path\n",
    "#     img_path = os.path.join(user_folder_path, filename)\n",
    "\n",
    "#     # Check if the file is an image (you can improve this check if needed)\n",
    "#     if img_path.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
    "#         process_image(img_path, user_folder_path, tesseract_ocr)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vkRv-Kvgawc_"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
